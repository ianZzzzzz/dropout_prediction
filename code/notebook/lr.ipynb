{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier \n","RF_C = RandomForestClassifier(\n","    #n_estimators=20,\n","    max_features=\"auto\",\n","    criterion='gini',\n","    #n_jobs=4,\n","    #oob_score=True\n","    ) \n","RF_C.fit(train_data_padding, list_label_train) \n","#int\n","predict_rfc = RF_C.predict(test_data_padding)   "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#LOAD \n","def prepare_label(dict_data)-> list:\n","    \"\"\"\n","        dict_data : { e_id: {\n","                            'log_features':[] ,\n","                            'info_features':[] ,\n","                            'label' : 1 or 0\n","                            } \n","                    }\n","\n","    Returns:\n","        list_assemble_data : [[ *log_features , *info_features ],......]\n","        list_e_id : [ e_id_1 ,e_id_2,...... ]\n","        list_label : [ 0, 1, ..........]\n","    \"\"\"    \n","    list_assemble_data = []\n","    list_e_id = []\n","    list_label = []\n","    for e_id,dict_ in dict_data.items():\n","\n","        log_data  = dict_['log_features']\n","        info_data = dict_['info_features']\n","        label     = dict_['label']\n","\n","        list_assemble_data.append([ *log_data,*info_data ])\n","        list_e_id.append(int(e_id))\n","        list_label.append(int(label))\n","\n","    return list_assemble_data , list_e_id , list_label\n","def assemble_predictedal_and_predict_label(\n","    list_label,\n","    list_e_id,\n","    predict_label)-> dict:\n","    \"\"\"\n","    Returns:\n","        dict: { e_id:[ predictedal_label , predict_label ]}\n","    \"\"\"    \n","    dict_ori_and_predict_label = {}\n","    for row in range(len(list_label)):\n","        e_id = list_e_id[row]\n","        ori_label = list_label[row]\n","        dict_ori_and_predict_label[e_id] = [ori_label,predict_label[row]]\n","\n","    return dict_ori_and_predict_label\n","\n","def predict_label_to_int(predict_label_list,threshold):\n","\n","    predict_label_int = []\n","    for i in predict_label:\n","        value= i\n","        if value >threshold:label_ = int(1)\n","        else:label_ = int(0)\n","        predict_label_int.append(label_)\n","\n","    return predict_label_int\n","def measure(predict_label_int,list_label_test):\n","    f1             = f1_score(predict_label_int,list_label_test)\n","    accuracy = accuracy_score(predict_label_int,list_label_test)\n","    AUC =       roc_auc_score(predict_label_int,list_label_test)\n","    # precision = precision_score(predict_label_int,test_label.tolist())\n","    # recall = recall_score(predict_label_int,test_label.tolist())\n","\n","    print(round(f1,4),round(AUC,4))\n","\n","import json\n","dict_data_train = json.load(open('after_processed_data_file\\\\dict_data_train_for_analy_fix_birth.json','r'))\n","dict_data_test = json.load(open('after_processed_data_file\\\\dict_data_test_for_analy_fix_birth.json','r'))\n","\n","list_data_train,list_e_id_train,list_label_train = prepare_label(dict_data_train)\n","list_data_test,list_e_id_test,list_label_test = prepare_label(dict_data_test)\n","\n","import numpy as np\n","train_data =np.array( list_data_train)\n","test_data  =np.array( list_data_test)\n","from sklearn.impute import SimpleImputer\n","Padding = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n","train_data_padding = Padding.fit_transform(train_data)\n","test_data_padding  = Padding.fit_transform(test_data)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier  #梯度提升树\n","GDBT = GradientBoostingClassifier(\n","   n_estimators=10,learning_rate=0.1,random_state=10\n","    )\n","GDBT.fit(train_data_padding,list_label_train)\n","# int\n","predict_gbdt = GDBT.predict(test_data_padding)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","LR = LogisticRegression(\n","   # max_iter = 100,solver='liblinear'\n","    )\n","LR.fit(train_data_padding,list_label_train)\n","# int\n","predict_lr = LR.predict(test_data_padding)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8583 0.5553\n","0.8925 0.8226\n","0.9015 0.8047\n"]}],"source":["\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score\n","for result in [\n","    predict_lr,\n","    predict_gbdt,\n","    predict_rfc,\n","   # predict_svm\n","    ]:\n","    measure(\n","        predict_label_int=result,\n","        list_label_test=list_label_test)\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import sklearn.model_selection  as Kfold\n","accs= Kfold.cross_validate(\n","    LR, train_data_padding, \n","    y=list_label_train, \n","    scoring=['roc_auc','f1'],cv=3, \n","    n_jobs=1)\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'fit_time': array([1.85818458, 2.14755273, 1.83001685, 1.87541986, 2.3081181 ,\n","        2.37367916, 2.3312583 , 1.3854022 , 2.00444174, 2.21884489]),\n"," 'score_time': array([0.05012918, 0.04400444, 0.03900266, 0.04000378, 0.05300307,\n","        0.04310679, 0.03201103, 0.02400374, 0.04252362, 0.04300189]),\n"," 'test_roc_auc': array([0.54731275, 0.45574588, 0.63490249, 0.61816644, 0.43423431,\n","        0.5001949 , 0.59820735, 0.59753766, 0.51308725, 0.56485497]),\n"," 'test_f1': array([0.85996227, 0.85759977, 0.85966377, 0.86003348, 0.85692464,\n","        0.86085128, 0.85951974, 0.85779766, 0.8592711 , 0.85677935])}"]},"metadata":{},"execution_count":15}],"source":["accs"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"'auc' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'auc'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32md:\\zyh\\_workspace\\dropout_prediction\\backup\\Final_preprocess_Pipline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist_label_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     n_jobs=-1)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    513\u001b[0m                                      f\"in the given list. Got {scoring!r}\")\n\u001b[0;32m    514\u001b[0m             scorers = {scorer: check_scoring(estimator, scoring=scorer)\n\u001b[1;32m--> 515\u001b[1;33m                        for scorer in scoring}\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{err_msg} Empty list was given. {scoring!r}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    513\u001b[0m                                      f\"in the given list. Got {scoring!r}\")\n\u001b[0;32m    514\u001b[0m             scorers = {scorer: check_scoring(estimator, scoring=scorer)\n\u001b[1;32m--> 515\u001b[1;33m                        for scorer in scoring}\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{err_msg} Empty list was given. {scoring!r}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    428\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    387\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0;32m    388\u001b[0m                              \u001b[1;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                              'to get valid options.' % scoring)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: 'auc' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."]}],"source":["import sklearn.model_selection  as Kfold\n","accs= Kfold.cross_validate(\n","    LR, train_data_padding, \n","    y=list_label_train, \n","    scoring=['auc','f1'],cv=10, \n","    n_jobs=-1)\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sklearn' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\zyh\\_workspace\\dropout_prediction\\backup\\Final_preprocess_Pipline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSCORERS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"]}],"source":["sklearn.metrics.SCORERS.keys()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import sklearn"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"]},"metadata":{},"execution_count":19}],"source":["sklearn.metrics.SCORERS.keys()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["predict_lr = LR.predict(test_data_padding)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8583 0.5553\n"]}],"source":["\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score\n","for result in [\n","    predict_lr,\n","   # predict_gbdt,\n","   # predict_rfc,\n","   # predict_svm\n","    ]:\n","    measure(\n","        predict_label_int=result,\n","        list_label_test=list_label_test)\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","LR = LogisticRegression(\n","   # max_iter = 100,solver='liblinear'\n","    )\n","LR.fit(train_data_padding,list_label_train)\n","# int\n","predict_lr = LR.predict(test_data_padding)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8583 0.5553\n"]}],"source":["\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score\n","for result in [\n","    predict_lr,\n","   # predict_gbdt,\n","   # predict_rfc,\n","   # predict_svm\n","    ]:\n","    measure(\n","        predict_label_int=result,\n","        list_label_test=list_label_test)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#LOAD \n","def prepare_label(dict_data)-> list:\n","    \"\"\"\n","        dict_data : { e_id: {\n","                            'log_features':[] ,\n","                            'info_features':[] ,\n","                            'label' : 1 or 0\n","                            } \n","                    }\n","\n","    Returns:\n","        list_assemble_data : [[ *log_features , *info_features ],......]\n","        list_e_id : [ e_id_1 ,e_id_2,...... ]\n","        list_label : [ 0, 1, ..........]\n","    \"\"\"    \n","    list_assemble_data = []\n","    list_e_id = []\n","    list_label = []\n","    for e_id,dict_ in dict_data.items():\n","\n","        log_data  = dict_['log_features']\n","        info_data = dict_['info_features']\n","        label     = dict_['label']\n","\n","        list_assemble_data.append([ *log_data,*info_data ])\n","        list_e_id.append(int(e_id))\n","        list_label.append(int(label))\n","\n","    return list_assemble_data , list_e_id , list_label\n","def assemble_predictedal_and_predict_label(\n","    list_label,\n","    list_e_id,\n","    predict_label)-> dict:\n","    \"\"\"\n","    Returns:\n","        dict: { e_id:[ predictedal_label , predict_label ]}\n","    \"\"\"    \n","    dict_ori_and_predict_label = {}\n","    for row in range(len(list_label)):\n","        e_id = list_e_id[row]\n","        ori_label = list_label[row]\n","        dict_ori_and_predict_label[e_id] = [ori_label,predict_label[row]]\n","\n","    return dict_ori_and_predict_label\n","\n","def predict_label_to_int(predict_label_list,threshold):\n","\n","    predict_label_int = []\n","    for i in predict_label:\n","        value= i\n","        if value >threshold:label_ = int(1)\n","        else:label_ = int(0)\n","        predict_label_int.append(label_)\n","\n","    return predict_label_int\n","def measure(predict_label_int,list_label_test):\n","    f1             = f1_score(predict_label_int,list_label_test)\n","    accuracy = accuracy_score(predict_label_int,list_label_test)\n","    AUC =       roc_auc_score(predict_label_int,list_label_test)\n","    # precision = precision_score(predict_label_int,test_label.tolist())\n","    # recall = recall_score(predict_label_int,test_label.tolist())\n","\n","    print(round(f1,4),round(AUC,4))\n","\n","import json\n","dict_data_train = json.load(open('after_processed_data_file\\\\dict_data_train_for_analy_fix_birth.json','r'))\n","dict_data_test = json.load(open('after_processed_data_file\\\\dict_data_test_for_analy_fix_birth.json','r'))\n","\n","list_data_train,list_e_id_train,list_label_train = prepare_label(dict_data_train)\n","list_data_test,list_e_id_test,list_label_test = prepare_label(dict_data_test)\n","\n","import numpy as np\n","train_data =np.array( list_data_train)\n","test_data  =np.array( list_data_test)\n","from sklearn.impute import SimpleImputer\n","Padding = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n","train_data_padding = Padding.fit_transform(train_data)\n","test_data_padding  = Padding.fit_transform(test_data)\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","LR = LogisticRegression(\n","   # max_iter = 100,solver='liblinear'\n","    )\n","LR.fit(train_data_padding,list_label_train)\n","# int\n","predict_lr = LR.predict(test_data_padding)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8583 0.5553\n"]}],"source":["\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import roc_auc_score\n","for result in [\n","    predict_lr,\n","   # predict_gbdt,\n","   # predict_rfc,\n","   # predict_svm\n","    ]:\n","    measure(\n","        predict_label_int=result,\n","        list_label_test=list_label_test)\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from sklearn import linear_model   \n","model = linear_model.LinearRegression()\n","model.fit(train_data_padding, list_label_train)\n","predict_LinearRegression = model.predict(test_data_padding)\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["\n","def predict_label_to_int(predict_label_list,threshold):\n","\n","    predict_label_int = []\n","    for i in predict_label_list:\n","        value= i\n","        if value >threshold:label_ = int(1)\n","        else:label_ = int(0)\n","        predict_label_int.append(label_)\n","\n","    return predict_label_int"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.866 0.8469\n"]}],"source":["from sklearn import linear_model   \n","model = linear_model.LinearRegression()\n","model.fit(train_data_padding, list_label_train)\n","predict_LinearRegression = predict_label_to_int(\n","    predict_label_list=model.predict(test_data_padding),\n","    threshold= 0.01)\n","measure(\n","    predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8583 0.5553\n","0.8583 0.5553\n","0.8583 0.5553\n","0.8583 0.5553\n","0.8583 0.5553\n"]}],"source":["for i in [0.01,0.02,0.03,0.04,0.05]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8583 0.5553\n","0.8583 0.5553\n","0.8583 0.5553\n","0.8583 0.5553\n","0.8583 0.5553\n"]}],"source":["for i in [0.1,0.2,0.3,0.4,0.5]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from sklearn import linear_model   \n","model = linear_model.LinearRegression()\n","model.fit(train_data_padding, list_label_train)\n","result = model.predict(test_data_padding)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.869 0.8446\n","0.8744 0.8408\n","0.8837 0.8358\n","0.8913 0.8216\n","0.8948 0.8017\n"]}],"source":["for i in [0.1,0.2,0.3,0.4,0.5]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.869 0.8446\n","0.8744 0.8408\n","0.8837 0.8358\n","0.8913 0.8216\n","0.8948 0.8017\n","0.8899 0.7717\n","0.8626 0.7322\n"]}],"source":["for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["#LOAD \n","def prepare_label(dict_data)-> list:\n","    \"\"\"\n","        dict_data : { e_id: {\n","                            'log_features':[] ,\n","                            'info_features':[] ,\n","                            'label' : 1 or 0\n","                            } \n","                    }\n","\n","    Returns:\n","        list_assemble_data : [[ *log_features , *info_features ],......]\n","        list_e_id : [ e_id_1 ,e_id_2,...... ]\n","        list_label : [ 0, 1, ..........]\n","    \"\"\"    \n","    list_assemble_data = []\n","    list_e_id = []\n","    list_label = []\n","    for e_id,dict_ in dict_data.items():\n","\n","        log_data  = dict_['log_features']\n","        info_data = dict_['info_features']\n","        label     = dict_['label']\n","\n","        list_assemble_data.append([ *log_data,*info_data ])\n","        list_e_id.append(int(e_id))\n","        list_label.append(int(label))\n","\n","    return list_assemble_data , list_e_id , list_label\n","def assemble_predictedal_and_predict_label(\n","    list_label,\n","    list_e_id,\n","    predict_label)-> dict:\n","    \"\"\"\n","    Returns:\n","        dict: { e_id:[ predictedal_label , predict_label ]}\n","    \"\"\"    \n","    dict_ori_and_predict_label = {}\n","    for row in range(len(list_label)):\n","        e_id = list_e_id[row]\n","        ori_label = list_label[row]\n","        dict_ori_and_predict_label[e_id] = [ori_label,predict_label[row]]\n","\n","    return dict_ori_and_predict_label\n","\n","def predict_label_to_int(predict_label_list,threshold):\n","\n","    predict_label_int = []\n","    for i in predict_label_list:\n","        value= i\n","        if value >threshold:label_ = int(1)\n","        else:label_ = int(0)\n","        predict_label_int.append(label_)\n","\n","    return predict_label_int\n","def measure(predict_label_int,list_label_test):\n","    f1             = f1_score(predict_label_int,list_label_test)\n","   # accuracy = accuracy_score(predict_label_int,list_label_test)\n","    AUC =       roc_auc_score(predict_label_int,list_label_test)\n","    # precision = precision_score(predict_label_int,test_label.tolist())\n","    # recall = recall_score(predict_label_int,test_label.tolist())\n","\n","    print(round(f1,4),round(AUC,4))\n","\n","import json\n","dict_data_train = json.load(open('after_processed_data_file\\\\dict_data_train_for_analy_fix_birth.json','r'))\n","dict_data_test = json.load(open('after_processed_data_file\\\\dict_data_test_for_analy_fix_birth.json','r'))\n","\n","list_data_train,list_e_id_train,list_label_train = prepare_label(dict_data_train)\n","list_data_test,list_e_id_test,list_label_test = prepare_label(dict_data_test)\n","\n","import numpy as np\n","train_data =np.array( list_data_train)\n","test_data  =np.array( list_data_test)\n","from sklearn.impute import SimpleImputer\n","Padding = SimpleImputer(missing_values=np.nan, strategy='mean')\n","train_data_padding = Padding.fit_transform(train_data)\n","test_data_padding  = Padding.fit_transform(test_data)\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["from sklearn import linear_model   \n","#linear_model.BayesianRidge()\n","\n","model = linear_model.LinearRegression()\n","model.fit(train_data_padding, list_label_train)\n","result = model.predict(test_data_padding)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8696 0.8436\n","0.8743 0.8393\n","0.8809 0.8313\n","0.8884 0.8216\n","0.8922 0.8005\n","0.8873 0.7661\n","0.8685 0.7322\n"]}],"source":["for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["\n","from sklearn import linear_model   \n","#linear_model.BayesianRidge()\n","\n","model = linear_model.LinearRegression(\n","    normalize=True\n","    ,n_jobs=-1)\n","model.fit(train_data_padding, list_label_train)\n","result = model.predict(test_data_padding)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8696 0.8436\n","0.8743 0.8393\n","0.8809 0.8313\n","0.8884 0.8216\n","0.8922 0.8005\n","0.8873 0.7661\n","0.8685 0.7322\n"]}],"source":["for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8669 0.8482\n","0.8682 0.8466\n","0.8688 0.8434\n","0.8696 0.8436\n","0.891 0.814\n","0.8922 0.8005\n","0.8906 0.7817\n","0.8873 0.7661\n"]}],"source":["for i in [0.01,0.05,0.075,0.1,0.45,0.5,0.55,0.6 ]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8668 0.8509\n","0.8921 0.8033\n","0.8922 0.8005\n","0.892 0.7963\n"]}],"source":["for i in [0.001, 0.49,0.5,0.51 ]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8668 0.8509\n","0.8921 0.8019\n","0.8922 0.8005\n","0.8919 0.7977\n"]}],"source":["for i in [0.001, 0.495,0.5,0.505 ]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8668 0.8509\n","0.8922 0.801\n","0.8922 0.8005\n","0.8922 0.8001\n"]}],"source":["for i in [0.001, 0.499,0.5,0.501 ]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["\n","from sklearn import linear_model   \n","bay = linear_model.BayesianRidge()\n","bay.fit(train_data_padding, list_label_train)\n","result_bay = bay.predict(test_data_padding)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8668 0.851\n","0.8921 0.8007\n","0.8921 0.8004\n","0.8922 0.8003\n"]}],"source":["for i in [0.001, 0.499,0.5,0.501 ]:\n","    predict_LinearRegression = predict_label_to_int(\n","        result_bay,\n","        threshold= i)\n","    measure(\n","        predict_LinearRegression,list_label_test)\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{},"execution_count":48}],"source":["model.rank_"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-6.95626262e-07,  3.78412327e-13, -6.16354821e-02,  6.93101649e-03,\n","       -1.93263421e-03,  1.87253767e-07, -1.95668043e-02,  3.10247895e-04,\n","       -1.12285668e-05, -5.16143230e-02, -7.82968360e-02, -1.27053239e-02,\n","        4.99977613e-02, -3.29189321e-05, -1.33033256e-02,  3.02063016e-02,\n","        3.64242152e-02, -4.54485230e-02, -1.55959567e-04,  5.19382963e-02,\n","        1.22203076e-02, -3.10052242e-02, -5.54236503e-02, -1.30756218e-03,\n","       -1.77658712e-02, -2.13416308e-03, -2.22020463e-03,  7.21602919e-04,\n","       -8.97060204e-13, -1.61490220e-09,  1.64478010e-05, -8.33870469e-04,\n","        5.91919769e-03,  6.75841022e-03])"]},"metadata":{},"execution_count":49}],"source":["model.coef_"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.1114952978474485"]},"metadata":{},"execution_count":50}],"source":["model.intercept_"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2.50302241e+00, 1.65889304e+00, 1.51659859e+00, 1.39438799e+00,\n","       1.37533018e+00, 1.33063379e+00, 1.29145872e+00, 1.19920296e+00,\n","       1.15970341e+00, 1.12813742e+00, 1.07046614e+00, 1.05340525e+00,\n","       1.00323629e+00, 9.83738141e-01, 9.25789122e-01, 9.11970090e-01,\n","       8.87049851e-01, 7.32331572e-01, 6.97012350e-01, 6.62516700e-01,\n","       6.51455891e-01, 5.97915652e-01, 5.86476028e-01, 4.70581954e-01,\n","       4.52536299e-01, 4.38906699e-01, 3.89548511e-01, 3.37182652e-01,\n","       2.99156334e-01, 2.89475277e-01, 5.13471760e-02, 1.41817154e-02,\n","       1.04010273e-02, 1.95265170e-16])"]},"metadata":{},"execution_count":51}],"source":["model.singular_"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}