<!DOCTYPE html>
<!-- saved from url=(0037)https://zhuanlan.zhihu.com/p/70257427 -->
<html lang="zh" data-hairline="true" data-theme="light" data-react-helmet="data-theme" style=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>XLNet:运行机制及和Bert的异同比较 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-react-helmet="true" name="keywords" content="人工智能,深度学习（Deep Learning）,自然语言处理"><meta data-react-helmet="true" name="description" content="这两天，XLNet貌似也引起了NLP圈的极大关注，从实验数据看，在某些场景下，确实XLNet相对Bert有很大幅度的提升。就像我们之前说的，感觉Bert打开两阶段模式的魔法盒开关后，在这条路上，会有越来越多的同行者，而X…"><meta data-react-helmet="true" property="og:title" content="XLNet:运行机制及和Bert的异同比较"><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/70257427"><meta data-react-helmet="true" property="og:description" content="这两天，XLNet貌似也引起了NLP圈的极大关注，从实验数据看，在某些场景下，确实XLNet相对Bert有很大幅度的提升。就像我们之前说的，感觉Bert打开两阶段模式的魔法盒开关后，在这条路上，会有越来越多的同行者，而X…"><meta data-react-helmet="true" property="og:image" content="https://pic1.zhimg.com/v2-205e42dbfd2e7de68ba1ab907136d69b_720w.jpg?source=172ae18b"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png" sizes="152x152"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.bbce8f18.png" sizes="120x120"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.cbade8f9.png" sizes="76x76"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.8f6c52aa.png" sizes="60x60"><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"><link rel="dns-prefetch" href="https://static.zhimg.com/"><link rel="dns-prefetch" href="https://pic1.zhimg.com/"><link rel="dns-prefetch" href="https://pic2.zhimg.com/"><link rel="dns-prefetch" href="https://pic3.zhimg.com/"><link rel="dns-prefetch" href="https://pic4.zhimg.com/"><style>
.u-safeAreaInset-top {
  height: constant(safe-area-inset-top) !important;
  height: env(safe-area-inset-top) !important;
  
}
.u-safeAreaInset-bottom {
  height: constant(safe-area-inset-bottom) !important;
  height: env(safe-area-inset-bottom) !important;
  
}
</style><link href="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.app.216a26f4.fefb2d0d3658904e782a.css" rel="stylesheet"><script defer="" crossorigin="anonymous" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/init.js.下载" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;1644-59deb79a&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#39;t find variable: webkit&quot;,&quot;Can&#39;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="qbubgm">.css-qbubgm{margin-left:0;}</style><script charset="utf-8" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.zswsdid.0b0add039d9dd177cf6b.js.下载"></script><link rel="stylesheet" type="text/css" href="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.user-hover-card.216a26f4.a21a39cedb849406303d.css"><script charset="utf-8" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.user-hover-card.e7c4799be5f1b5d67d0a.js.下载"></script><link rel="stylesheet" type="text/css" href="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.Labels.216a26f4.7d19d2afdc588e36471f.css"><script charset="utf-8" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.Labels.c6e771959aa7a3a6ede4.js.下载"></script><link rel="stylesheet" type="text/css" href="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.modals.216a26f4.6b0a511460867b1595f8.css"><script charset="utf-8" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.modals.56d7b3b41216c1d0aa44.js.下载"></script><link rel="stylesheet" type="text/css" href="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.comments-modals.216a26f4.39d2b57c6fd2cae24672.css"><script charset="utf-8" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.comments-modals.fab05b4a0701d6188c6e.js.下载"></script><style data-emotion="css"></style><link rel="stylesheet" type="text/css" href="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.richinput.216a26f4.d7eb544a00018fff1eb6.css"><script charset="utf-8" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.richinput.c568fe7bed73a5dd538e.js.下载"></script></head><body class="WhiteBg-body" data-react-helmet="class"><div id="root"><div class="App"><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;张俊林&quot;,&quot;itemId&quot;:70257427,&quot;title&quot;:&quot;XLNet:运行机制及和Bert的异同比较&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;70257427&quot;}}}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader is-fixed" style="width: 1519.2px; top: 0px; left: 0px;"><div class="ColumnPageHeader-content"><a class="ZhihuLogoLink" href="https://www.zhihu.com/" aria-label="知乎"><svg viewBox="0 0 64 30" fill="#0066FF" width="64" height="30"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="https://www.zhihu.com/column/c_188941548">深度学习前沿笔记</a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg>写文章</button></div></div></div><div class="Sticky--holder" style="position: relative; inset: 0px; display: block; float: none; margin: 0px; height: 52px;"></div></div></div><img class="TitleImage" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-205e42dbfd2e7de68ba1ab907136d69b_1440w.jpg" alt="XLNet:运行机制及和Bert的异同比较"><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">XLNet:运行机制及和Bert的异同比较</h1><div class="Post-Author"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="张俊林"><meta itemprop="image" content="https://pic2.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/zhang-jun-lin-76"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover11-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover11-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg" srcset="https://pic2.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b 2x" alt="张俊林"></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover12-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover12-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></div></div></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText">你所不知道的事</div></div></div></div></div></div><div class="LabelContainer-wrapper"></div><div><span class="Voters"><button type="button" class="Button Button--plain">1,472 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText"><p>这两天，XLNet貌似也引起了NLP圈的极大关注，从实验数据看，在某些场景下，确实XLNet相对Bert有很大幅度的提升。就像我们之前说的，感觉Bert打开两阶段模式的魔法盒开关后，在这条路上，会有越来越多的同行者，而XLNet就是其中比较引人注目的一位。当然，我估计很快我们会看到更多的这个模式下的新工作。未来两年，在两阶段新模式（预训练+Finetuning）下，应该会有更多的好工作涌现出来。根本原因在于：这个模式的潜力还没有被充分挖掘，貌似还有很大的提升空间。当然，这也意味着NLP在未来两年会有各种技术或者应用的突破，现在其实是进入NLP领域非常好的时机。原因有两个，一个是NLP正面临一个技术栈大的改朝换代的时刻，有很多空白等着你去填补，容易出成绩；另外一点，貌似Bert+Transformer有统一NLP各个应用领域的趋向，这意味着此时进入NLP领域，具备学习成本非常低的好处，和之前相比，投入产出比非常合算。这是两个原因。当然，即使如此，想要学好NLP，持续的精力投入是必不可少的。有句老话说得好：“永恒的爱大约持续三个月”，这句话其实对于很多对NLP感兴趣的同学也成立：“对NLP的永恒的热情大约能够持续3到5天”，希望真的有兴趣的同学能坚持一下，起码持续7到8天，凑够一个星期…..</p><p>那么XLNet和Bert比，有什么异同？有什么模型方面的改进？在哪些场景下特别有效？原因又是什么？本文通过论文思想解读及实验结果分析，试图回答上述问题。</p><p>首先，XLNet引入了自回归语言模型以及自编码语言模型的提法，这个思维框架我觉得挺好的，可以先简单说明下。</p><p class="ztext-empty-paragraph"><br></p><p><b>自回归语言模型（Autoregressive LM）</b></p><p>   在ELMO／BERT出来之前，大家通常讲的语言模型其实是根据上文内容预测下一个可能跟随的单词，就是常说的自左向右的语言模型任务，或者反过来也行，就是根据下文预测前面的单词，这种类型的LM被称为自回归语言模型。GPT 就是典型的自回归语言模型。ELMO尽管看上去利用了上文，也利用了下文，但是本质上仍然是自回归LM，这个跟模型具体怎么实现有关系。ELMO是做了两个方向（从左到右以及从右到左两个方向的语言模型），但是是分别有两个方向的自回归LM，然后把LSTM的两个方向的隐节点状态拼接到一起，来体现双向语言模型这个事情的。所以其实是两个自回归语言模型的拼接，本质上仍然是自回归语言模型。</p><p>自回归语言模型有优点有缺点，缺点是只能利用上文或者下文的信息，不能同时利用上文和下文的信息，当然，貌似ELMO这种双向都做，然后拼接看上去能够解决这个问题，因为融合模式过于简单，所以效果其实并不是太好。它的优点，其实跟下游NLP任务有关，比如生成类NLP任务，比如文本摘要，机器翻译等，在实际生成内容的时候，就是从左向右的，自回归语言模型天然匹配这个过程。而Bert这种DAE模式，在生成类NLP任务中，就面临训练过程和应用过程不一致的问题，导致生成类的NLP任务到目前为止都做不太好。</p><p><b>自编码语言模型（Autoencoder LM）</b></p><p>自回归语言模型只能根据上文预测下一个单词，或者反过来，只能根据下文预测前面一个单词。相比而言，Bert通过在输入X中随机Mask掉一部分单词，然后预训练过程的主要任务之一是根据上下文单词来预测这些被Mask掉的单词，如果你对Denoising Autoencoder比较熟悉的话，会看出，这确实是典型的DAE的思路。那些被Mask掉的单词就是在输入侧加入的所谓噪音。类似Bert这种预训练模式，被称为DAE LM。</p><p>这种DAE LM的优缺点正好和自回归LM反过来，它能比较自然地融入双向语言模型，同时看到被预测单词的上文和下文，这是好处。缺点是啥呢？主要在输入侧引入[Mask]标记，导致预训练阶段和Fine-tuning阶段不一致的问题，因为Fine-tuning阶段是看不到[Mask]标记的。DAE吗，就要引入噪音，[Mask] 标记就是引入噪音的手段，这个正常。</p><p>XLNet的出发点就是：能否融合自回归LM和DAE LM两者的优点。就是说如果站在自回归LM的角度，如何引入和双向语言模型等价的效果；如果站在DAE LM的角度看，它本身是融入双向语言模型的，如何抛掉表面的那个[Mask]标记，让预训练和Fine-tuning保持一致。当然，XLNet还讲到了一个Bert被Mask单词之间相互独立的问题，我相信这个不太重要，原因后面会说。当然，我认为这点不重要的事情，纯粹是个人观点，出错难免，看看就完了，不用较真。</p><h2><b>XLNet做了些什么</b></h2><p>上文说过，Bert这种自编码语言模型的好处是：能够同时利用上文和下文，所以信息利用充分。对于很多NLP任务而言，典型的比如阅读理解，在解决问题的时候，是能够同时看到上文和下文的，所以当然应该把下文利用起来。在Bert原始论文中，与GPT1.0的实验对比分析也可以看出来，BERT相对GPT 1.0的性能提升，主要来自于双向语言模型与单向语言模型的差异。这是Bert的好处，很明显，Bert之后的改进模型，如果不能把双向语言模型用起来，那明显是很吃亏的。当然，GPT 2.0的作者不信这个邪，坚持沿用GPT 1.0 单向语言模型的旧瓶，装进去了更高质量更大规模预训练数据的新酒，而它的实验结果也说明了，如果想改善预训练语言模型，走这条扩充预序列模型训练数据的路子，是个多快好但是不省钱的方向。这也进一步说明了，预训练LM这条路，还远远没有走完，还有很大的提升空间，比如最简单的提升方法就是加大数据规模，提升数据质量。</p><p>但是Bert的自编码语言模型也有对应的缺点，就是XLNet在文中指出的，第一个预训练阶段因为采取引入[Mask]标记来Mask掉部分单词的训练模式，而Fine-tuning阶段是看不到这种被强行加入的Mask标记的，所以两个阶段存在使用模式不一致的情形，这可能会带来一定的性能损失；另外一个是，Bert在第一个预训练阶段，假设句子中多个单词被Mask掉，这些被Mask掉的单词之间没有任何关系，是条件独立的，而有时候这些单词之间是有关系的，XLNet则考虑了这种关系（关于这点原因是否可靠，后面会专门分析）。</p><p>上面两点是XLNet在第一个预训练阶段，相对Bert来说要解决的两个问题。</p><p>其实从另外一个角度更好理解XLNet的初衷和做法，我觉得这个估计是XLNet作者真正的思考出发点，是啥呢？就是说自回归语言模型有个缺点，要么从左到右，要么从右到左，尽管可以类似ELMO两个都做，然后再拼接的方式。但是跟Bert比，效果明显不足够好（这里面有RNN弱于Transformer的因素，也有双向语言模型怎么做的因素）。那么，能不能类似Bert那样，比较充分地在自回归语言模型中，引入双向语言模型呢？因为Bert已经证明了这是非常关键的一点。这一点，想法简单，但是看上去貌似不太好做，因为从左向右的语言模型，如果我们当前根据上文，要预测某个单词Ti，那么看上去它没法看到下文的内容。具体怎么做才能让这个模型：看上去仍然是从左向右的输入和预测模式，但是其实内部已经引入了当前单词的下文信息呢？XLNet在模型方面的主要贡献其实是在这里。</p><p>那么XLNet是怎么做到这一点的呢？其实思路也比较简洁，可以这么思考：XLNet仍然遵循两阶段的过程，第一个阶段是语言模型预训练阶段；第二阶段是任务数据Fine-tuning阶段。它主要希望改动第一个阶段，就是说不像Bert那种带Mask符号的Denoising-autoencoder的模式，而是采用自回归LM的模式。就是说，看上去输入句子X仍然是自左向右的输入，看到Ti单词的上文Context_before，来预测Ti这个单词。但是又希望在Context_before里，不仅仅看到上文单词，也能看到Ti单词后面的下文Context_after里的下文单词，这样的话，Bert里面预训练阶段引入的Mask符号就不需要了，于是在预训练阶段，看上去是个标准的从左向右过程，Fine-tuning当然也是这个过程，于是两个环节就统一起来。当然，这是目标。剩下是怎么做到这一点的问题。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-05d785e9d8f810d118e4fa93f8e9b39f_b.jpg" data-rawwidth="1680" data-rawheight="1228" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="1680" data-original="https://pic4.zhimg.com/v2-05d785e9d8f810d118e4fa93f8e9b39f_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-05d785e9d8f810d118e4fa93f8e9b39f_720w.jpg" data-rawwidth="1680" data-rawheight="1228" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="1680" data-original="https://pic4.zhimg.com/v2-05d785e9d8f810d118e4fa93f8e9b39f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-05d785e9d8f810d118e4fa93f8e9b39f_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p>那么，怎么能够在单词Ti的上文中Contenxt_before中揉入下文Context_after的内容呢？你可以想想。XLNet是这么做的，在预训练阶段，引入Permutation Language Model的训练目标。什么意思呢？就是说，比如包含单词Ti的当前输入的句子X，由顺序的几个单词构成，比如x1,x2,x3,x4四个单词顺序构成。我们假设，其中，要预测的单词Ti是x3，位置在Position 3，要想让它能够在上文Context_before中，也就是Position 1或者Position 2的位置看到Position 4的单词x4。可以这么做：假设我们固定住x3所在位置，就是它仍然在Position 3，之后随机排列组合句子中的4个单词，在随机排列组合后的各种可能里，再选择一部分作为模型预训练的输入X。比如随机排列组合后，抽取出x4,x2，x3,x1这一个排列组合作为模型的输入X。于是，x3就能同时看到上文x2，以及下文x4的内容了。这就是XLNet的基本思想，所以说，看了这个就可以理解上面讲的它的初衷了吧：看上去仍然是个自回归的从左到右的语言模型，但是其实通过对句子中单词排列组合，把一部分Ti下文的单词排到Ti的上文位置中，于是，就看到了上文和下文，但是形式上看上去仍然是从左到右在预测后一个单词。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-948e085be7a9a2eb7eac2d12069b1a93_b.jpg" data-rawwidth="1484" data-rawheight="838" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="1484" data-original="https://pic4.zhimg.com/v2-948e085be7a9a2eb7eac2d12069b1a93_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-948e085be7a9a2eb7eac2d12069b1a93_720w.jpg" data-rawwidth="1484" data-rawheight="838" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="1484" data-original="https://pic4.zhimg.com/v2-948e085be7a9a2eb7eac2d12069b1a93_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-948e085be7a9a2eb7eac2d12069b1a93_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p>当然，上面讲的仍然是基本思想。难点其实在于具体怎么做才能实现上述思想。首先，需要强调一点，尽管上面讲的是把句子X的单词排列组合后，再随机抽取例子作为输入，但是，实际上你是不能这么做的，因为Fine-tuning阶段你不可能也去排列组合原始输入。所以，就必须让预训练阶段的输入部分，看上去仍然是x1,x2,x3,x4这个输入顺序，但是可以在Transformer部分做些工作，来达成我们希望的目标。具体而言，XLNet采取了Attention掩码的机制，你可以理解为，当前的输入句子是X，要预测的单词Ti是第i个单词，前面1到i-1个单词，在输入部分观察，并没发生变化，该是谁还是谁。但是在Transformer内部，通过Attention掩码，从X的输入单词里面，也就是Ti的上文和下文单词中，随机选择i-1个，放到Ti的上文位置中，把其它单词的输入通过Attention掩码隐藏掉，于是就能够达成我们期望的目标（当然这个所谓放到Ti的上文位置，只是一种形象的说法，其实在内部，就是通过Attention Mask，把其它没有被选到的单词Mask掉，不让它们在预测单词Ti的时候发生作用，如此而已。看着就类似于把这些被选中的单词放到了上文Context_before的位置了）。具体实现的时候，XLNet是用“双流自注意力模型”实现的，细节可以参考论文，但是基本思想就如上所述，双流自注意力机制只是实现这个思想的具体方式，理论上，你可以想出其它具体实现方式来实现这个基本思想，也能达成让Ti看到下文单词的目标。</p><p>这里简单说下“双流自注意力机制”，一个是内容流自注意力，其实就是标准的Transformer的计算过程；主要是引入了Query流自注意力，这个是干嘛的呢？其实就是用来代替Bert的那个[Mask]标记的，因为XLNet希望抛掉[Mask]标记符号，但是比如知道上文单词x1,x2，要预测单词x3，此时在x3对应位置的Transformer最高层去预测这个单词，但是输入侧不能看到要预测的单词x3，Bert其实是直接引入[Mask]标记来覆盖掉单词x3的内容的，等于说[Mask]是个通用的占位符号。而XLNet因为要抛掉[Mask]标记，但是又不能看到x3的输入，于是Query流，就直接忽略掉x3输入了，只保留这个位置信息，用参数w来代表位置的embedding编码。其实XLNet只是扔了表面的[Mask]占位符号，内部还是引入Query流来忽略掉被Mask的这个单词。和Bert比，只是实现方式不同而已。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-2bb1a60af4fe2fa751647fdce48e337c_b.jpg" data-rawwidth="2824" data-rawheight="1544" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2824" data-original="https://pic1.zhimg.com/v2-2bb1a60af4fe2fa751647fdce48e337c_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-2bb1a60af4fe2fa751647fdce48e337c_720w.jpg" data-rawwidth="2824" data-rawheight="1544" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2824" data-original="https://pic1.zhimg.com/v2-2bb1a60af4fe2fa751647fdce48e337c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2bb1a60af4fe2fa751647fdce48e337c_b.jpg" data-lazy-status="ok"></figure><p>上面说的Attention掩码，我估计你还是没了解它的意思，我再用例子解释一下。Attention Mask的机制，核心就是说，尽管当前输入看上去仍然是x1-&gt;x2-&gt;x3-&gt;x4，但是我们已经改成随机排列组合的另外一个顺序x3-&gt;x2-&gt;x4-&gt;x1了，如果用这个例子用来从左到右训练LM，意味着当预测x2的时候，它只能看到上文x3；当预测x4的时候，只能看到上文x3和x2，以此类推……这样，比如对于x2来说，就看到了下文x3了。这种在输入侧维持表面的X句子单词顺序，但是其实在Transformer内部，看到的已经是被重新排列组合后的顺序，是通过Attention掩码来实现的。如上图所示，输入看上去仍然是x1,x2,x3,x4，可以通过不同的掩码矩阵，让当前单词Xi只能看到被排列组合后的顺序x3-&gt;x2-&gt;x4-&gt;x1中自己前面的单词。这样就在内部改成了被预测单词同时看到上下文单词，但是输入侧看上去仍然维持原先的单词顺序了。关键要看明白上图右侧那个掩码矩阵，我相信很多人刚开始没看明白，因为我刚开始也没看明白，因为没有标出掩码矩阵的单词坐标，它的坐标是1-2-3-4，就是表面那个X的单词顺序，通过掩码矩阵，就能改成你想要的排列组合，并让当前单词看到它该看到的所谓上文，其实是掺杂了上文和下文的内容。这是attention mask来实现排列组合的背后的意思。</p><p>上面讲的Permutation Language Model是XLNet的主要理论创新，所以介绍的比较多，从模型角度讲，这个创新还是挺有意思的，因为它开启了自回归语言模型如何引入下文的一个思路，相信对于后续工作会有启发。当然，XLNet不仅仅做了这些，它还引入了其它的因素，也算是一个当前有效技术的集成体。感觉XLNet就是Bert、GPT 2.0和Transformer XL的综合体变身，首先，它通过PLM预训练目标，吸收了Bert的双向语言模型；然后，GPT2.0的核心其实是更多更高质量的预训练数据，这个明显也被XLNet吸收进来了；再然后，Transformer XL的主要思想也被吸收进来，它的主要目标是解决Transformer对于长文档NLP应用不够友好的问题。</p><p>以上是XLNet的几个主要改进点，有模型创新方面的，有其它模型引入方面的，也有数据扩充方面的。那么，这些因素各自起到了什么作用呢？在后面我们会谈。在谈不同因素各自作用之前，我们先分析下XLNet和Bert的异同问题。</p><p class="ztext-empty-paragraph"><br></p><h2><b>与Bert的预训练过程的异同问题</b></h2><p>  尽管看上去，XLNet在预训练机制引入的Permutation Language Model这种新的预训练目标，和Bert采用Mask标记这种方式，有很大不同。其实你深入思考一下，会发现，两者本质是类似的。区别主要在于：Bert是直接在输入端显示地通过引入Mask标记，在输入侧隐藏掉一部分单词，让这些单词在预测的时候不发挥作用，要求利用上下文中其它单词去预测某个被Mask掉的单词；而XLNet则抛弃掉输入侧的Mask标记，通过Attention Mask机制，在Transformer内部随机Mask掉一部分单词（这个被Mask掉的单词比例跟当前单词在句子中的位置有关系，位置越靠前，被Mask掉的比例越高，位置越靠后，被Mask掉的比例越低），让这些被Mask掉的单词在预测某个单词的时候不发生作用。所以，本质上两者并没什么太大的不同，只是Mask的位置，Bert更表面化一些，XLNet则把这个过程隐藏在了Transformer内部而已。这样，就可以抛掉表面的[Mask]标记，解决它所说的预训练里带有[Mask]标记导致的和Fine-tuning过程不一致的问题。至于说XLNet说的，Bert里面被Mask掉单词的相互独立问题，也就是说，在预测某个被Mask单词的时候，其它被Mask单词不起作用，这个问题，你深入思考一下，其实是不重要的，因为XLNet在内部Attention Mask的时候，也会Mask掉一定比例的上下文单词，只要有一部分被Mask掉的单词，其实就面临这个问题。而如果训练数据足够大，其实不靠当前这个例子，靠其它例子，也能弥补被Mask单词直接的相互关系问题，因为总有其它例子能够学会这些单词的相互依赖关系。</p><p>我相信，通过改造Bert的预训练过程，其实是可以模拟XLNet的Permutation Language Model过程的：Bert目前的做法是，给定输入句子X，随机Mask掉15%的单词，然后要求利用剩下的85%的单词去预测任意一个被Mask掉的单词，被Mask掉的单词在这个过程中相互之间没有发挥作用。如果我们把Bert的预训练过程改造成：对于输入句子，随机选择其中任意一个单词Ti，只把这个单词改成Mask标记，假设Ti在句子中是第i个单词，那么此时随机选择X中的任意i个单词，只用这i个单词去预测被Mask掉的单词。当然，这个过程理论上也可以在Transformer内采用attention mask来实现。如果是这样，其实Bert的预训练模式就和XLNet是基本等价的了。</p><p>或者换个角度思考，假设仍然利用Bert目前的Mask机制，但是把Mask掉15%这个条件极端化，改成，每次一个句子只Mask掉一个单词，利用剩下的单词来预测被Mask掉的单词。那么，这个过程其实跟XLNet的PLM也是比较相像的，区别主要在于每次预测被Mask掉的单词的时候，利用的上下文更多一些（XLNet在实现的时候，为了提升效率，其实也是选择每个句子最后末尾的1/K单词被预测，假设K=7，意味着一个句子X，只有末尾的1/7的单词会被预测，这意味着什么呢？意味着至少保留了6/7的Context单词去预测某个单词，对于最末尾的单词，意味着保留了所有的句子中X的其它单词，这其实和上面提到的Bert只保留一个被Mask单词是一样的）。或者我们站在Bert预训练的角度来考虑XLNet，如果XLNet改成对于句子X，只需要预测句子中最后一个单词，而不是最后的1/K（就是假设K特别大的情况），那么其实和Bert每个输入句子只Mask掉一个单词，两者基本是等价的。</p><p>当然，XLNet这种改造，维持了表面看上去的自回归语言模型的从左向右的模式，这个Bert做不到，这个有明显的好处，就是对于生成类的任务，能够在维持表面从左向右的生成过程前提下，模型里隐含了上下文的信息。所以看上去，XLNet貌似应该对于生成类型的NLP任务，会比Bert有明显优势。另外，因为XLNet还引入了Transformer XL的机制，所以对于长文档输入类型的NLP任务，也会比Bert有明显优势。</p><p class="ztext-empty-paragraph"><br></p><h2><b>哪些因素在起作用？</b></h2><p>如上分析，XLNet有个好处，但是感觉同时也是个问题，那就是：XLNet其实同时引入了很多因素在模型里。说是好处，因为实验证明了这样效果确实好，即使是跟Bert_Large这种非常强的基准模型比也是，尤其是长文档任务，这个效果提升比较明显；说是问题，是因为其实应该在实验部分充分说明，如果模型起了作用，这些因素各自发挥了多大作用，尤其是在跟Bert进行对比的时候，感觉应该把数据规模这个变量磨平进行比较，因为这才是单纯的模型差异导致的性能差异，而不是训练数据量引发的差异。当然，XLNet最后一组实验是把这个预训练数据规模差异磨平后，和Bert比较的，所以信息含量更大些。而前面的几组实验，因为天然存在预训练数据量的差异，所以模型导致的差异到底有多大，看得不太明显。</p><p>我们上文提到过，XLNet起作用的，如果宏观归纳一下，共有三个因素；</p><p>1. 与Bert采取De-noising Autoencoder方式不同的新的预训练目标：Permutation Language Model(简称PLM)；这个可以理解为在自回归LM模式下，如何采取具体手段，来融入双向语言模型。这个是XLNet在模型角度比较大的贡献，确实也打开了NLP中两阶段模式潮流的一个新思路。</p><p>2. 引入了Transformer-XL的主要思路：相对位置编码以及分段RNN机制。实践已经证明这两点对于长文档任务是很有帮助的；</p><p>3. 加大增加了预训练阶段使用的数据规模；Bert使用的预训练数据是BooksCorpus和英文Wiki数据，大小13G。XLNet除了使用这些数据外，另外引入了Giga5，ClueWeb以及Common Crawl数据，并排掉了其中的一些低质量数据，大小分别是16G,19G和78G。可以看出，在预训练阶段极大扩充了数据规模，并对质量进行了筛选过滤。这个明显走的是GPT2.0的路线。</p><p>所以实验部分需要仔细分析，提升到底是上述哪个因素或者是哪几个因素导致的性能提升？</p><p>我们把实验分成几个部分来分析。</p><p>首先，给人最大的印象是：XLNet对于阅读理解类任务，相对Bert，性能有极大幅度地提升。下面是论文报道的实验结果：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-368cb8e6f8b2eeacabe1d2638dd12cb2_b.jpg" data-rawwidth="2838" data-rawheight="1558" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2838" data-original="https://pic3.zhimg.com/v2-368cb8e6f8b2eeacabe1d2638dd12cb2_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-368cb8e6f8b2eeacabe1d2638dd12cb2_720w.jpg" data-rawwidth="2838" data-rawheight="1558" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2838" data-original="https://pic3.zhimg.com/v2-368cb8e6f8b2eeacabe1d2638dd12cb2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-368cb8e6f8b2eeacabe1d2638dd12cb2_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-9c854303cd62b5ef22a0b2c2a01a72f2_b.jpg" data-rawwidth="2880" data-rawheight="1800" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2880" data-original="https://pic3.zhimg.com/v2-9c854303cd62b5ef22a0b2c2a01a72f2_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-9c854303cd62b5ef22a0b2c2a01a72f2_720w.jpg" data-rawwidth="2880" data-rawheight="1800" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2880" data-original="https://pic3.zhimg.com/v2-9c854303cd62b5ef22a0b2c2a01a72f2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9c854303cd62b5ef22a0b2c2a01a72f2_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p>其中，RACE和SQuAD 2.0是文档长度较长的阅读理解任务，任务难度也相对高。可以看出，在这两个任务中，XLNet相对 Bert_Large，确实有大幅性能提升（Race提升13.5%,SQuAD 2.0 F1指标提升8.6）。在Squad1.1上提升尽管稍微小些，F1提升3.9%，但是因为基准高，所以提升也比较明显。</p><p>说XLNet在阅读理解，尤其是长文档的阅读理解中，性能大幅超过Bert，这个是没疑问的。但是，因为XLNet融入了上文说的三个因素，所以不确定每个因素在其中起的作用有多大，而对于长文档，Transformer XL的引入肯定起了比较大的作用，Bert天然在这种类型任务中有缺点，其它两类因素的作用不清楚。感觉这里应该增加一个基准，就是Bert用与XLNet相同大小的预训练数据做，这样抹平数据量差异，更好比较模型差异带来的效果差异。当然，我觉得即使是这样，XLNet应该仍然是比Bert效果好的，只是可能不会差距这么大，因为XLNet的长文档优势肯定会起作用。</p><p>下面我们看下其它类型的NLP任务。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-18c8752f5c9dac8c6de11337a8efb453_b.jpg" data-rawwidth="2702" data-rawheight="1520" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2702" data-original="https://pic4.zhimg.com/v2-18c8752f5c9dac8c6de11337a8efb453_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-18c8752f5c9dac8c6de11337a8efb453_720w.jpg" data-rawwidth="2702" data-rawheight="1520" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2702" data-original="https://pic4.zhimg.com/v2-18c8752f5c9dac8c6de11337a8efb453_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-18c8752f5c9dac8c6de11337a8efb453_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p>GLUE是个综合的NLP任务集合，包含各种类型的任务，因为ensemble模式里面包含了各种花式的trick，所以重点看上面一组实验，这里比较单纯。从实验数据看，XLNet相对Bert也有性能提升，当然不像阅读理解提升那么大，而且性能提升比较大的集中在RTE，MNLI和COLA数据集合，其它任务提升效果还好。而我一直觉得，RTE在GLUE里，是个神奇的存在，如果没有它，很多论文的效果可能没法看，这个是闲话，先不讲了，后面我会单说。</p><p> 当然，仍然不确定这种性能提升主要来自于XLNet的哪个因素，或者哪几个因素各自的贡献，尤其是如果Bert加大预训练数据规模后，两者性能差异有多大。感觉这里Transformer XL的因素可能发挥的作用不会太大，其它两个因素在起作用，但是作用未知，这里感觉应该补充其它实验。</p><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-78cc6b83fcf24f1f2b89922d217f597f_b.jpg" data-rawwidth="2734" data-rawheight="1530" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2734" data-original="https://pic4.zhimg.com/v2-78cc6b83fcf24f1f2b89922d217f597f_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-78cc6b83fcf24f1f2b89922d217f597f_720w.jpg" data-rawwidth="2734" data-rawheight="1530" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2734" data-original="https://pic4.zhimg.com/v2-78cc6b83fcf24f1f2b89922d217f597f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-78cc6b83fcf24f1f2b89922d217f597f_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-2d2651c3e9b5bd28237db65171baa46f_b.jpg" data-rawwidth="2812" data-rawheight="1554" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2812" data-original="https://pic4.zhimg.com/v2-2d2651c3e9b5bd28237db65171baa46f_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-2d2651c3e9b5bd28237db65171baa46f_720w.jpg" data-rawwidth="2812" data-rawheight="1554" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2812" data-original="https://pic4.zhimg.com/v2-2d2651c3e9b5bd28237db65171baa46f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-2d2651c3e9b5bd28237db65171baa46f_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p>上面是文本分类任务和信息检索任务，可以看出，相对Bert，XLNet效果有提升，但是幅度不算大。仍然是上面的考虑，起作用的三个因素，到底哪个发挥多大作用，从数据方面看不太出来。</p><p>下面一组实验可以仔细分析一下，这组实验是排除掉上述第三个数据规模因素的实验的对比，就是说XLNet用的是和Bert相同规模的预训练数据，所以与Bert对比更具备模型方面的可比较性，而没有数据规模的影响。实验结果如下：</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-86f738620973ec16395c99480db4239d_b.jpg" data-rawwidth="2682" data-rawheight="1526" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb" width="2682" data-original="https://pic2.zhimg.com/v2-86f738620973ec16395c99480db4239d_r.jpg"/></noscript><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-86f738620973ec16395c99480db4239d_720w.jpg" data-rawwidth="2682" data-rawheight="1526" data-size="normal" data-caption="" class="origin_image zh-lightbox-thumb lazy" width="2682" data-original="https://pic2.zhimg.com/v2-86f738620973ec16395c99480db4239d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-86f738620973ec16395c99480db4239d_b.jpg" data-lazy-status="ok"></figure><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><p>如果仔细分析实验数据，实验结果说明：</p><p>因为和Bert比较，XLNet使用相同的预训练数据。所以两者的性能差异来自于：Permutation Language Model预训练目标以及Transformer XL的长文档因素。而从中可以看出，DAE+Transformer XL体现的是长文档因素的差异，和Bert比，Race提升1个点，SQuAD F1提升3个点，MNLI提升0.5个点，SST-2性能稍微下降。这是Transformer XL因素解决长文档因素带来的收益，很明显，长文档阅读理解任务提升比较明显，其它任务提升不太明显。</p><p> 而通过XLNet进一步和DAE+Transformer XL及Bert比，这一点应该拆解出Permutation Language Model和Mask的方式差异。可以看出：XLNet相对DAE+Transformer XL来说，Race进一步提升1个点左右；SQuAD进一步提升1.8个点左右，NMLI提升1个点左右，SST-B提升不到1个点。虽然不精准，但是大致是能说明问题的，这个应该大致是PLM带来的模型收益。可以看出，PLM还是普遍有效的，但是提升幅度并非特别巨大。</p><p> 如果我们结合前面Race和SQuAD的实验结果看（上面两组实验是三个因素的作用，后面是排除掉数据量差异的结果，所以两者的差距，很可能就是第三个因素：数据规模导致的差异，当然，因为一个是Bert_base，一个是Bert_Large，所以不具备完全可比性，但是大致估计不会偏离真实结论太远），Race数据集合三因素同时具备的XLNet，超过Bert绝对值大约9个多百分点，Transformer因素+PLM因素估计贡献大约在2到4个点之间，那么意味着预训练数据量导致的差异大概在4到5个点左右；类似的，可以看出，SQuAD 2.0中，预训练数据量导致的差异大约在2到3个点左右，也就是说，估计训练数据量带来的提升，在阅读理解任务中大约占比30%到40%左右。 </p><p>  如果从实验结果归纳一下的话，可以看出：XLNet综合而言，效果是优于Bert的，尤其是在长文档类型任务，效果提升明显。如果进一步拆解的话，因为对比实验不足，只能做个粗略的结论：预训练数据量的提升，大概带来30%左右的性能提升，其它两个模型因素带来剩余的大约70%的性能提升。当然，这个主要指的是XLNet性能提升比较明显的阅读理解类任务而言。对于其它类型任务，感觉Transformer XL的因素贡献估计不会太大，主要应该是其它两个因素在起作用。</p><p class="ztext-empty-paragraph"><br></p><h2><b>对NLP应用任务的影响</b></h2><p> XLNet其实本质上还是ELMO／GPT／Bert这一系列两阶段模型的进一步延伸。在将自回归LM方向引入双向语言模型方面，感觉打开了一个新思路，这点还是非常对人有启发的。当然，如果深入思考，其实和Bert并没有太大的不同。</p><p> 如果让我推论下XLNet的出现，对后续NLP工作的影响，我觉得跟Bert比，最直接的影响应该有两个，一个是对于Bert长文档的应用，因为Transformer天然对长文档任务处理有弱点，所以XLNet对于长文档NLP任务相比Bert应该有直接且比较明显的性能提升作用，它在论文中也证明了这点。所以，以后长文档类型的NLP应用，XLNet明显跟Bert比占优势。当然，你说我把Transformer XL的因素引入Bert，然后继续在Bert上做改进，明显这也是可以的。</p><p> 第二点，对于生成类的NLP任务，到目前为止，尽管出了一些改进模型，但是从效果看，Bert仍然不能很好地处理。而因为XLNet的预训练模式天然符合下游任务序列生成结果，所以按理说能够直接通过引入XLNet来改进生成类NLP任务的效果。所以，这点估计是XLNet会明显占优势的一个领域。</p><p> 可以预计的是，很快我们就会看到XLNet在文本摘要，机器翻译，信息检索…..等符合上述XLNet应用领域特点和优势领域的应用结果，以及在这些任务上的进一步改进模型。当然，这个有点比手速的意思，有意者请尽快动手把结果扔出来。</p><p> 又给你了一个拼手速的机会，加油吧，少年！</p></div></div><div class="ContentItem-time">编辑于 2019-06-22</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19551275&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19551275" target="_blank"><div class="Popover"><div id="Popover1-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover1-content">人工智能</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19813032&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19813032" target="_blank"><div class="Popover"><div id="Popover2-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover2-content">深度学习（Deep Learning）</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19560026&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19560026" target="_blank"><div class="Popover"><div id="Popover3-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover3-content">自然语言处理</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 690px; bottom: 0px; left: 414.6px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;70257427&quot;}}}"><span><button aria-label="赞同 1472 " type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span>赞同 1472</button><button aria-label="反对" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><div class="css-qbubgm"><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span>106 条评论</button></div><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover4-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover4-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span>分享</button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Heart Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2 8.437C2 5.505 4.294 3.094 7.207 3 9.243 3 11.092 4.19 12 6c.823-1.758 2.649-3 4.651-3C19.545 3 22 5.507 22 8.432 22 16.24 13.842 21 12 21 10.158 21 2 16.24 2 8.437z" fill-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span>收藏</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover5-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover5-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div class="Post-SideActions" style="opacity: 1;"><button class="like"><div class="Post-SideActions-icon"><svg class="Zi Zi--TriangleUp Post-SideActions-upIcon" fill="currentColor" viewBox="0 0 24 24" width="16" height="16"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></div><div class="likeCount"><div class="likeCount-inner" data-previous="已赞同 1473">赞同 1472</div></div></button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover60-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover60-content"><img class="ShareMenu-fakeQRCode" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/qrcode" alt="微信二维码"><button><div class="Post-SideActions-icon"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Share" fill="currentColor" viewBox="0 0 24 24" width="20" height="20"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span></div>分享</button></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px 0px 10px; height: 54px;"></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://www.zhihu.com/column/c_188941548"><div class="Popover"><div id="Popover6-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover6-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-a19621dc409ca054f1630c09679a41ff_xs.jpg" srcset="https://pic2.zhimg.com/v2-a19621dc409ca054f1630c09679a41ff_l.jpg?source=172ae18b 2x" alt="深度学习前沿笔记"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="https://www.zhihu.com/column/c_188941548"><div class="Popover"><div id="Popover7-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover7-content">深度学习前沿笔记</div></div></a></h2><div class="ContentItem-meta">深度学习领域前沿进展科普</div></div><div class="ContentItem-extra"><a href="https://www.zhihu.com/column/c_188941548" type="button" class="Button">进入专栏</a></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://www.zhihu.com/column/c_1280888532622143488"><div class="Popover"><div id="Popover8-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover8-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/4b70deef7_xs.jpg" srcset="https://pic1.zhimg.com/4b70deef7_l.jpg?source=172ae18b 2x" alt="好文"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="https://www.zhihu.com/column/c_1280888532622143488"><div class="Popover"><div id="Popover9-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover9-content">好文</div></div></a></h2><div class="ContentItem-meta">收集看到的高赞解析和回答</div></div><div class="ContentItem-extra"><a href="https://www.zhihu.com/column/c_1280888532622143488" type="button" class="Button">进入专栏</a></div></div></div></ul></div><div class="Recommendations-Main" style="width: 1519px;"><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class="Recommendations-List"><button class="PagingButton PagingButton-Previous" disabled="" data-za-detail-view-path-module="Unknown" data-za-detail-view-path-module_name="推荐阅读" data-za-extra-module="{}"><svg class="Zi Zi--ArrowLeft" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M14.782 16.78a.737.737 0 0 1-1.052 0L9.218 12.53a.758.758 0 0 1 0-1.063L13.73 7.22a.737.737 0 0 1 1.052 0c.29.294.29.77.001 1.063L11 12l3.782 3.716c.29.294.29.77 0 1.063z" fill-rule="evenodd"></path></svg></button><a href="https://zhuanlan.zhihu.com/p/44121378" class="PostItem"><div><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-f8d834e3e3387b67f81c8c8c20c3c34d_250x0.jpg" srcset="https://pic1.zhimg.com/v2-f8d834e3e3387b67f81c8c8c20c3c34d_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="【NLP】Transformer模型原理详解"><h1 class="PostItem-Title">【NLP】Transformer模型原理详解</h1><div class="PostItem-Footer"><span>李rumor</span><span class="PostItem-FooterTitle"></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/76912493" class="PostItem"><div><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-0e78a280939451bef50bc0b1a521c45b_250x0.jpg" srcset="https://pic1.zhimg.com/v2-0e78a280939451bef50bc0b1a521c45b_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="nlp中的预训练语言模型总结(单向模型、BERT系列模型、XLNet)"><h1 class="PostItem-Title">nlp中的预训练语言模型总结(单向模型、BERT系列模型、XLNet)</h1><div class="PostItem-Footer"><span>JayLo...</span><span class="PostItem-FooterTitle">发表于高能NLP</span></div></div></a><a href="https://zhuanlan.zhihu.com/p/54743941" class="PostItem"><div><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-427d3a804d490704ac70fb8d5c0a7fe7_250x0.jpg" srcset="https://pic1.zhimg.com/v2-427d3a804d490704ac70fb8d5c0a7fe7_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较"><h1 class="PostItem-Title">放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较</h1><div class="PostItem-Footer"><span>张俊林</span><span class="PostItem-FooterTitle">发表于深度学习前...</span></div></div></a><a href="https://zhuanlan.zhihu.com/p/70318222" class="PostItem"><div><img src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-588036a4293fa99e6142d6fc5191e5ca_250x0.jpg" srcset="https://pic4.zhimg.com/v2-588036a4293fa99e6142d6fc5191e5ca_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="讲讲我理解的XLNet"><h1 class="PostItem-Title">讲讲我理解的XLNet</h1><div class="PostItem-Footer"><span>蔡杰</span><span class="PostItem-FooterTitle">发表于AI部落</span></div></div></a><button class="PagingButton PagingButton-Next" data-za-detail-view-path-module="Unknown" data-za-detail-view-path-module_name="推荐阅读" data-za-extra-module="{}"><svg class="Zi Zi--ArrowRight" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M9.218 16.78a.737.737 0 0 0 1.052 0l4.512-4.249a.758.758 0 0 0 0-1.063L10.27 7.22a.737.737 0 0 0-1.052 0 .759.759 0 0 0-.001 1.063L13 12l-3.782 3.716a.758.758 0 0 0 0 1.063z" fill-rule="evenodd"></path></svg></button></ul></div><div class="Comments-container" data-za-detail-view-path-module="CommentList" data-za-extra-module="{}"><div class="CommentsV2 CommentsV2--withEditor CommentsV2-withPagination"><div class="Topbar CommentTopbar"><div class="Topbar-title"><h2 class="CommentTopbar-title">106 条评论</h2></div><div class="Topbar-options"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Switch Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M13.004 7V4.232c0-.405.35-.733.781-.733.183 0 .36.06.501.17l6.437 5.033c.331.26.376.722.1 1.033a.803.803 0 0 1-.601.264H2.75a.75.75 0 0 1-.75-.75V7.75A.75.75 0 0 1 2.75 7h10.254zm-1.997 9.999v2.768c0 .405-.35.733-.782.733a.814.814 0 0 1-.5-.17l-6.437-5.034a.702.702 0 0 1-.1-1.032.803.803 0 0 1 .6-.264H21.25a.75.75 0 0 1 .75.75v1.499a.75.75 0 0 1-.75.75H11.007z" fill-rule="evenodd"></path></svg></span>切换为时间排序</button></div></div><div><div class="CommentsV2-footer CommentEditorV2--normal"><div class="CommentEditorV2-inputWrap"><div class="InputLike CommentEditorV2-input Editable"><div class="Dropzone Editable-content RichText RichText--editable RichText--clearBoth ztext" style="min-height: 198px;"><div class="DraftEditor-root"><div class="public-DraftEditorPlaceholder-root"><div class="public-DraftEditorPlaceholder-inner" id="placeholder-g03o" style="white-space: pre-wrap;">写下你的评论...</div></div><div class="DraftEditor-editorContainer"><div aria-describedby="placeholder-g03o" class="notranslate public-DraftEditor-content" contenteditable="true" role="textbox" spellcheck="true" tabindex="0" style="outline: none; user-select: text; white-space: pre-wrap; overflow-wrap: break-word;"><div data-contents="true"><div class="Editable-unstyled" data-block="true" data-editor="g03o" data-offset-key="8ucci-0-0"><div data-offset-key="8ucci-0-0" class="public-DraftStyleDefault-block public-DraftStyleDefault-ltr"><span data-offset-key="8ucci-0-0"><br data-text="true"></span></div></div></div></div></div></div></div><input multiple="" type="file" accept="image/webp,image/jpg,image/jpeg,image/png,image/gif" style="display: none;"><div></div></div><div class="CommentEditorV2-inputUpload"><div class="CommentEditorV2-popoverWrap"><div class="Popover CommentEditorV2-inputUpLoad-Icon"><button aria-label="插入表情" data-tooltip="插入表情" data-tooltip-position="bottom" data-tooltip-will-hide-on-click="true" id="Popover10-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover10-content" type="button" class="Button Editable-control Button--plain"><svg class="Zi Zi--Emotion" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M7.523 13.5h8.954c-.228 2.47-2.145 4-4.477 4-2.332 0-4.25-1.53-4.477-4zM12 21a9 9 0 1 1 0-18 9 9 0 0 1 0 18zm0-1.5a7.5 7.5 0 1 0 0-15 7.5 7.5 0 0 0 0 15zm-3-8a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3zm6 0a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3z"></path></svg></button></div></div></div></div><button type="button" disabled="" class="Button CommentEditorV2-singleButton Button--primary Button--blue">发布</button></div></div><div><div class="CommentListV2"><div class="CommentListV2-header-divider">精选评论（2）</div><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover15-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover15-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yychenca"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="ChrisCC"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yychenca">ChrisCC</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">XL一出来就期待张老师的分析，肖老师的XL as a service以及狼老师的 XL pytorch</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>21</button><button type="button" class="Button CommentItemV2-talkBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Comments" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M11 2c5.571 0 9 4.335 9 8 0 6-6.475 9.764-11.481 8.022-.315-.07-.379-.124-.78.078-1.455.54-2.413.921-3.525 1.122-.483.087-.916-.25-.588-.581 0 0 .677-.417.842-1.904.064-.351-.14-.879-.454-1.171A8.833 8.833 0 0 1 2 10c0-3.87 3.394-8 9-8zm10.14 9.628c.758.988.86 2.009.86 3.15 0 1.195-.619 3.11-1.368 3.938-.209.23-.354.467-.308.722.12 1.073.614 1.501.614 1.501.237.239-.188.562-.537.5-.803-.146-1.495-.42-2.546-.811-.29-.146-.336-.106-.563-.057-2.043.711-4.398.475-6.083-.927 5.965-.524 8.727-3.03 9.93-8.016z" fill-rule="evenodd"></path></svg></span>查看回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><div class="NestComment-nextSiblings--noBorder"></div><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(1).jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/xinyi-li-61">leexinyi</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>肖涵的 bert-as-service 和 Thomas Wolf 的 huggingface/pytorch-pretrained-BERT 吧</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>21</button><button type="button" class="Button CommentItemV2-talkBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Comments" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M11 2c5.571 0 9 4.335 9 8 0 6-6.475 9.764-11.481 8.022-.315-.07-.379-.124-.78.078-1.455.54-2.413.921-3.525 1.122-.483.087-.916-.25-.588-.581 0 0 .677-.417.842-1.904.064-.351-.14-.879-.454-1.171A8.833 8.833 0 0 1 2 10c0-3.87 3.394-8 9-8zm10.14 9.628c.758.988.86 2.009.86 3.15 0 1.195-.619 3.11-1.368 3.938-.209.23-.354.467-.308.722.12 1.073.614 1.501.614 1.501.237.239-.188.562-.537.5-.803-.146-1.495-.42-2.546-.811-.29-.146-.336-.106-.563-.057-2.043.711-4.398.475-6.083-.927 5.965-.524 8.727-3.03 9.93-8.016z" fill-rule="evenodd"></path></svg></span>查看回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><div class="CommentListV2-header-divider">评论（106）</div><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover16-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover16-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ted-li-36"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/e2654a24d9324d731fd53943c933c445_s.jpg" srcset="https://pic1.zhimg.com/e2654a24d9324d731fd53943c933c445_xs.jpg?source=06d4cd63 2x" alt="Ted Li"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ted-li-36">Ted Li</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">感谢张老师</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>7</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover17-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover17-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s.jpg" srcset="https://pic1.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ted-li-36">Ted Li</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">客气</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover18-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover18-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yychenca"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="ChrisCC"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yychenca">ChrisCC</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">XL一出来就期待张老师的分析，肖老师的XL as a service以及狼老师的 XL pytorch</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>21</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover19-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover19-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/a5a81395965c1489824141436493d435"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/770a7fec2_s.jpg" srcset="https://pic1.zhimg.com/50/770a7fec2_xs.jpg?source=06d4cd63 2x" alt="张翔"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/a5a81395965c1489824141436493d435">张翔</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/14ab9ba9507dcd65b84f056ad63b3c46">ChrisCC</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">排队催更</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover20-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover20-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/045d2b4696da9136145c4b5cc08b9c86"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/e2654a24d9324d731fd53943c933c445_s(1).jpg" srcset="https://pic2.zhimg.com/50/e2654a24d9324d731fd53943c933c445_xs.jpg?source=06d4cd63 2x" alt="Ted Li"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/045d2b4696da9136145c4b5cc08b9c86">Ted Li</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/14ab9ba9507dcd65b84f056ad63b3c46">ChrisCC</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">你怎么偷偷给老师们安排了这么多活</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>11</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><div><div class="CommentMoreReplyButton"><button type="button" class="Button Button--plain">查看全部 10 条回复</button></div></div></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover21-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover21-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/tang-li-78-82"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/e20d806bf73131b68a386208ded42b0a_s.jpg" srcset="https://pic3.zhimg.com/e20d806bf73131b68a386208ded42b0a_xs.jpg?source=06d4cd63 2x" alt="唐立"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/tang-li-78-82">唐立</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>感谢，感谢，上午刚看完原文就看到了这篇文章</p><div class="Richtext-content_img Richtext-content_img-square"><img class="comment_sticker" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-fa3cb6bc9ec57da84ab53a60f48d0c6f.gif" data-original="https://pic4.zhimg.com/v2-fa3cb6bc9ec57da84ab53a60f48d0c6f_r.gif" data-rawwidth="NaN"></div></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover22-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover22-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(1).jpg" srcset="https://pic4.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/tang-li-78-82">唐立</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">客气啦</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover23-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover23-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/nicholasbao-59"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="Nicholasbao"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/nicholasbao-59">Nicholasbao</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">谢谢张老师</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover24-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover24-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(2).jpg" srcset="https://pic2.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/nicholasbao-59">Nicholasbao</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">感谢支持</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover25-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover25-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/xiao-bai-55-47"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-88ec487d1d28ad4b51dfe7553c12bf33_s.jpg" srcset="https://pic1.zhimg.com/v2-88ec487d1d28ad4b51dfe7553c12bf33_xs.jpg?source=06d4cd63 2x" alt="逆名用户"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/xiao-bai-55-47">逆名用户</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>谢谢张老师</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover26-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover26-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(2).jpg" srcset="https://pic2.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/xiao-bai-55-47">逆名用户</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">客气</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">有中文的预训练模型吗？不知道拿来做生成式的闲聊怎么样</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover27-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover27-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(2).jpg" srcset="https://pic2.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">据说放出来了，不确定是否有中文</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover28-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover28-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/alexhong"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-fd92e1cd6c55f98c5cda97b073def495_s.jpg" srcset="https://pic1.zhimg.com/v2-fd92e1cd6c55f98c5cda97b073def495_xs.jpg?source=06d4cd63 2x" alt="alexhong"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/alexhong">alexhong</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>感谢张老师 有英文的预训练模型，中文的应该还没有</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover29-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover29-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/wu-xing-39-41"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-871b33f8af603b958c4c75e4c64bd726_s.jpg" srcset="https://pic2.zhimg.com/v2-871b33f8af603b958c4c75e4c64bd726_xs.jpg?source=06d4cd63 2x" alt="伍星"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/wu-xing-39-41">伍星</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content CommentItemV2-shield"><div class="RichText ztext">该评论已删除</div></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover30-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover30-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/147bf0c743d6aa5ccea428a6f4cc7186"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(3).jpg" srcset="https://pic1.zhimg.com/50/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/147bf0c743d6aa5ccea428a6f4cc7186">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/b79b3387e0d20b79f63882458ed431ae">伍星</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">当然，你觉得做好了也没问题[微笑]</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover31-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover31-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/b79b3387e0d20b79f63882458ed431ae"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-871b33f8af603b958c4c75e4c64bd726_s(1).jpg" srcset="https://pic1.zhimg.com/50/v2-871b33f8af603b958c4c75e4c64bd726_xs.jpg?source=06d4cd63 2x" alt="伍星"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/b79b3387e0d20b79f63882458ed431ae">伍星</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/147bf0c743d6aa5ccea428a6f4cc7186">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">😢我的理解是，在生成任务上表现不好，不是因为训练和应用过程不一致的问题，而是BERT本身就是个Encoder(或者说DAE本身是为了学习表示的),所以它一般需要借助其他的Decoder去做生成。所以觉得这里的因果写的不是很能理解，个人浅见。</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>1</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover58-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover58-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/147bf0c743d6aa5ccea428a6f4cc7186"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(4).jpg" srcset="https://pic2.zhimg.com/50/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/147bf0c743d6aa5ccea428a6f4cc7186">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/b79b3387e0d20b79f63882458ed431ae">伍星</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">嗯，bert生成做不好根本还是预训练的mask模式同时看到上文和下文，decoder没法达到这一点，原因应该还是在mask这种模式上</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>2</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><div></div></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(2).jpg" srcset="https://pic2.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">好像没有做生成任务，如果有提升的话作者肯定会说，估计生成任务也未必超过bert</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(3).jpg" srcset="https://pic3.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-reply">回复</span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>这个过分了，这篇文章在 RACE/SQUAD/GLUE 上做这么多实验已经工作量很大了（而且即便这样还是有些变量没有控制好，例如 BERT-Large 数据量的问题），不能强求作者把生成也包括进来，那可以作为另一篇文章了。</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(3).jpg" srcset="https://pic3.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-reply">回复</span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-27</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>据说作者正在做，估计稍后会有更新</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover32-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover32-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ju-cheng-37"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-82be2bd4b9275cc219f4520d7b89c86f_s.jpg" srcset="https://pic1.zhimg.com/v2-82be2bd4b9275cc219f4520d7b89c86f_xs.jpg?source=06d4cd63 2x" alt="Tobias Lee"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ju-cheng-37">Tobias Lee</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>"只要有一部分被Mask掉的单词，其实就面临这个问题"，我觉得 PLM 应该是解决了这个问题。</p><p>拿文中的 The city is New York 来说，如果 MASK 了 New 和 York，那么在这个 case 里的 loss 里计算 New 和 York 的概率时候彼此都不会作为条件出现；但是 PLM，计算排列中靠后 masked token 的时候还是会把靠前的 token 加入概率的计算的吧？</p><p>当然，如果数据量够大，这个问题自然迎刃而解，这点完全赞同张老师的看法。</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>3</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover33-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover33-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(1).jpg" srcset="https://pic4.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/ju-cheng-37">Tobias Lee</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">这个句子太短可能不太好看出来，如果换个长的句子，用链式法则，在预测句子中某个单词的时候，假设是第i个单词，它也只能看到context中i-1个单词，其它单词也看不到，意味着也有部分单词关系没有考虑。这是从训练过程中一个步骤来说的。对于第i个单词，它也无法看全所有上下文，只有最后一个单词才能看到所有上下文，才没有这个问题。</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>4</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover34-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover34-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/antares-38"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(1).jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="Antares"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/antares-38">Antares</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-time">2019-08-30</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>张老师你好, 关于 [只要有一部分被Mask掉的单词，其实就面临这个问题] 这一点我想和您讨论一下. </p><p>我的理解是这样的: BERT 在训练过程中mask掉 15% 的 tokens, 也就是说每一个 token prediction 只能依赖 剩下的 85%的context; 而XLNet 在训练过程中, 同样可以看作有15%左右(K=7)的 tokens 被 mask 掉了, 但是这里有个不同, XLNet 是以AR的形式 predict 的, 也就是说 有一些 token prediction 是可以看到更多的 context的 (这个prediction过程中最后的一个 token 可以看到其他所有 tokens). 这个不同意味着 XLNet 是有机会学习 [如何利用更非富的 context 信息] 的. BERT 因为永远只能看到 85% 的 context, 可能就没有这样的机会. 我理解这是作者在文中想表达的 PLM 的优势. </p><p>我认为 XLNet 在 [去掉 independence assumption] 这件事情上 和 BERT 是有不同的. 期待您的回复</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>4</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><div><div class="CommentMoreReplyButton"><button type="button" class="Button Button--plain">展开其他 1 条回复</button></div></div></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover35-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover35-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-chi-21-31-71"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-def45800cfd3ed852f4b998c7a4a6ed0_s.jpg" srcset="https://pic4.zhimg.com/v2-def45800cfd3ed852f4b998c7a4a6ed0_xs.jpg?source=06d4cd63 2x" alt="张伟男"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-chi-21-31-71">张伟男</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">赞张老师，又是在车上看完的[酷]，有个问题张老师怎么看sample操作的影响呢？您觉得这块是不是训练时候比较重要的部分呢？</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover36-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover36-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s.jpg" srcset="https://pic1.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-chi-21-31-71">张伟男</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">张老师好，我觉得sample可能是没有办法的事情，它这个排列组合会极大增加训练数据规模，貌似只能采样了，否则数据量估计太大做不了</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>2</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover37-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover37-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhou-han-han-mei-tian-yao-jin-bu"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-da63391be65950c4315277ad2035e2b6_s.jpg" srcset="https://pic1.zhimg.com/v2-da63391be65950c4315277ad2035e2b6_xs.jpg?source=06d4cd63 2x" alt="super涵"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhou-han-han-mei-tian-yao-jin-bu">super涵</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>感谢张老师的精彩解读！！XL这种预训练方法虽然表面是看起来是自左至右，但实际还是在transformer中用到了预测词后边的词，这样的话在生成任务中怎么更好适配呢。bert，或者改进的XL，在生成任务上都没有相关的试验，这也是GPT坚持单向语言模型的原因吧。。</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhou-han-han-mei-tian-yao-jin-bu">super涵</a></span><span class="CommentItemV2-time">2019-06-22</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>BERT 都能做生成（详见 BERT has a mouth，虽然 Cho 在博客里说这篇文章的数学公式有点问题，但生成算法是可以用的，没记错的话还有代码），XLNet 更容易做（最次也可以用 left-to-right factorization 做）。以后生成的趋势我觉得是并行生成 + 多次 refine，所以访问后面的单词没什么问题（就好像你写文章，也不一定完全按顺序写，先写后一段再补上前一段也可以）。</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>4</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover38-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover38-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yychenca"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(3).jpg" srcset="https://pic3.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="ChrisCC"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/yychenca">ChrisCC</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">狼老师已经发推了………搓手手中</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover39-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover39-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/wxd6992bac365f76dc"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="wxd6992bac365f76dc"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/wxd6992bac365f76dc">wxd6992bac365f76dc</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">您好，张老师，我是大数据文摘的编辑~这篇非常棒~我想转载到大数据文摘微信公众号上上面~转载时会注明来源与作者~还请您给授权呀~</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover40-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover40-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-e2f0287f28b654a03136ca1900c92cb5_s(2).jpg" srcset="https://pic2.zhimg.com/v2-e2f0287f28b654a03136ca1900c92cb5_xs.jpg?source=06d4cd63 2x" alt="张俊林"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zhang-jun-lin-76">张俊林</a></span><span class="CommentItemV2-roleInfo"> (作者) </span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/wxd6992bac365f76dc">wxd6992bac365f76dc</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">私信吧</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s(1).jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">刚刚学完elmo以及bert……<br>技术更新不等人啊</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>3</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="知乎用户"></span><span class="UserLink">知乎用户</span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">又给你了一个拼手速的机会，加油吧，少年！哈哈哈哈</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>1</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover41-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover41-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/pray-90-47"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="pray"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/pray-90-47">pray</a></span><span class="CommentItemV2-time">2019-06-23</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">必属精品</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover42-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover42-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/chen-yu-20-54"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-ea5559764611aa5c605903ca32baae3a_s.jpg" srcset="https://pic4.zhimg.com/v2-ea5559764611aa5c605903ca32baae3a_xs.jpg?source=06d4cd63 2x" alt="陈裕"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/chen-yu-20-54">陈裕</a></span><span class="CommentItemV2-time">2019-06-24</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext">忽然有个想法，如果引入一个强化学习过程，利用前面的词的信息去预测下文的词的掩码情况，或者直接采样得到预测的下文的词并且和前面的词组合作为内部注意力层的输入。不知道这个方法可行性怎样？</div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootComment"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover43-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover43-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zrx-54-79"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="ZRX"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zrx-54-79">ZRX</a></span><span class="CommentItemV2-time">2019-06-24</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>张博士，有个不明白的地方请教下：既然BERT的主要问题在于难处理长文档和输入Mask机制导致两阶段不一致，长文档由transformer-xl搞定，所以相比于bert而言xlnet主要改进的是bert的mask机制，把input中显式mask挪到self-attention阶段调制mask，从而解决了两阶段不一致问题。问题是，既然都认可bert中双向lm的重要性，为什么不在调制attention是对于待预测词wi的对input sequence中除了wi外的其他所有词进行attention（只mask自己，为防止see itself over prediction）而非得向单向lm靠拢（搞出一个要预测wi at position index n，attention时只在input sequence except wi中随机挑n-1个词进行attention其他都masked）呢？如果是为了seq2seq生成式任务，可这样也并不能解决问题啊，因为bert/xlnet都是表示模型，只为了学习到语言深度的语义信息表示，其作用等同于seq2seq模型中的encoder；要完成生成式任务总得有decoder吧而在decoder中有个seq2seq mask机制保障了output word by word时只能参考前面生成的word。另外，xlnet通过随机在input seqence中挑n-1进行attention的硬向自回归lm靠拢的方法即使在数据足够多时可以等效地（原则上）实现双向lm上下文都可见的语义表示，但难道效率不低下吗？（毕竟，相比于complete self-attention每次只attention比较少的context信息）</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>6</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover44-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover44-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/void-7"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/v2-99fa2c04d71780046ab1b8fc870ffd59_s.jpg" srcset="https://pic4.zhimg.com/v2-99fa2c04d71780046ab1b8fc870ffd59_xs.jpg?source=06d4cd63 2x" alt="uvzu"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/void-7">uvzu</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zrx-54-79">ZRX</a></span><span class="CommentItemV2-time">2019-06-25</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>我的理解是，PLM预训练本身首先是个语言模型，通过上文预测下一个单词，不过这里的“上文”通过factorization permutation所以包含了下文信息。transformer也是有decoder的吧，不太理解为什么你说“其作用等同于seq2seq模型中的encoder”，求张老师回答</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><li class="NestComment--child"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover45-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover45-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zrx-54-79"><img class="Avatar UserLink-avatar" width="24" height="24" src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/da8e974dc_s.jpg" srcset="https://pic1.zhimg.com/da8e974dc_xs.jpg?source=06d4cd63 2x" alt="ZRX"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/zrx-54-79">ZRX</a></span><span class="CommentItemV2-reply">回复</span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/void-7">uvzu</a></span><span class="CommentItemV2-time">2019-06-27</span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p>attention is all u need论文中transformer是encoder + decoder两大组件的，因为目的是为了seq2seq；而bert和xlnet只利用了native transformer中的encoder组件，因为目的是为了学习representation</p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>赞</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span>踩</button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;">​<svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span>举报</button></div></div></div></div></li><div><div class="CommentMoreReplyButton"><button type="button" class="Button Button--plain">查看全部 9 条回复</button></div></div></ul></div><div class="Pagination CommentsV2-pagination"><button type="button" disabled="" class="Button PaginationButton PaginationButton--current Button--plain">1</button><button type="button" class="Button PaginationButton Button--plain">2</button><button type="button" class="Button PaginationButton Button--plain">3</button><button type="button" class="Button PaginationButton PaginationButton-next Button--plain">下一页</button></div><div class="CommentListV2"><div></div><div></div></div></div></div></div></div></div></main><div class="CornerButtons"><div class="CornerAnimayedFlex CornerAnimayedFlex--hidden"><button data-tooltip="回到顶部" data-tooltip-position="left" data-tooltip-will-hide-on-click="true" aria-label="回到顶部" type="button" class="Button CornerButton Button--plain"><svg class="Zi Zi--BackToTop" aria-label="回到顶部" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M16.036 19.59a1 1 0 0 1-.997.995H9.032a.996.996 0 0 1-.997-.996v-7.005H5.03c-1.1 0-1.36-.633-.578-1.416L11.33 4.29a1.003 1.003 0 0 1 1.412 0l6.878 6.88c.782.78.523 1.415-.58 1.415h-3.004v7.005z"></path></svg></button></div></div></div></div><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com"}}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"club":{"tags":{},"admins":{"data":[]},"members":{"data":[]},"explore":{"candidateSyncClubs":{}},"profile":{},"checkin":{},"comments":{"paging":{},"loading":{},"meta":{},"ids":{}},"postList":{"paging":{},"loading":{},"ids":{}},"recommend":{"data":[]},"silences":{"data":[]},"application":{"profile":null}},"entities":{"users":{"zhang-jun-lin-76":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5.jpg?source=172ae18b","uid":"37478916423680","userType":"people","isFollowing":false,"urlToken":"zhang-jun-lin-76","id":"147bf0c743d6aa5ccea428a6f4cc7186","description":"Heil Hydra！嗯","name":"张俊林","isAdvertiser":false,"headline":"你所不知道的事","gender":1,"url":"\u002Fpeople\u002F147bf0c743d6aa5ccea428a6f4cc7186","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b","isOrg":false,"type":"people","levelInfo":{"exp":142406,"level":8,"nicknameColor":{"color":"","nightModeColor":""},"levelIcon":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ce2d9b858d70d9e107f14c57a0ceb563_l.png","iconInfo":{"url":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ce2d9b858d70d9e107f14c57a0ceb563_l.png","nightModeUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2c1a38e54e53ce62f8b7bc346a043c61_l.png","width":93,"height":51}},"badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972478580856496128","medalName":"专栏作家","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c6395b66f4bf91be3056666c4ae80867_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2675240add1d7e06c796232ba0f0ba64_l.png?source=172ae18b","description":"开通专栏并收获 1000 关注"}}},"questions":{},"answers":{},"articles":{"70257427":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"id":70257427,"title":"XLNet:运行机制及和Bert的异同比较","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F70257427","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-205e42dbfd2e7de68ba1ab907136d69b_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-205e42dbfd2e7de68ba1ab907136d69b_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-05d785e9d8f810d118e4fa93f8e9b39f_200x112.jpg\" data-rawwidth=\"1680\" data-rawheight=\"1228\" data-size=\"normal\" data-caption=\"\" data-watermark=\"\" data-original-src=\"\" data-watermark-src=\"\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-05d785e9d8f810d118e4fa93f8e9b39f_r.jpg\"\u002F\u003E这两天，XLNet貌似也引起了NLP圈的极大关注，从实验数据看，在某些场景下，确实XLNet相对Bert有很大幅度的提升。就像我们之前说的，感觉Bert打开两阶段模式的魔法盒开关后，在这条路上，会有越来越多的同行者，而XLNet就是其中比较引人注目的一位。当然，我…","created":1561171796,"updated":1561199578,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5.jpg?source=172ae18b","uid":"37478916423680","userType":"people","isFollowing":false,"urlToken":"zhang-jun-lin-76","id":"147bf0c743d6aa5ccea428a6f4cc7186","description":"Heil Hydra！嗯","name":"张俊林","isAdvertiser":false,"headline":"你所不知道的事","gender":1,"url":"\u002Fpeople\u002F147bf0c743d6aa5ccea428a6f4cc7186","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b","isOrg":false,"type":"people","levelInfo":{"exp":142406,"level":8,"nicknameColor":{"color":"","nightModeColor":""},"levelIcon":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ce2d9b858d70d9e107f14c57a0ceb563_l.png","iconInfo":{"url":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ce2d9b858d70d9e107f14c57a0ceb563_l.png","nightModeUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2c1a38e54e53ce62f8b7bc346a043c61_l.png","width":93,"height":51}},"badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972478580856496128","medalName":"专栏作家","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c6395b66f4bf91be3056666c4ae80867_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2675240add1d7e06c796232ba0f0ba64_l.png?source=172ae18b","description":"开通专栏并收获 1000 关注"}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","imageWidth":1920,"imageHeight":1080,"content":"\u003Cp\u003E这两天，XLNet貌似也引起了NLP圈的极大关注，从实验数据看，在某些场景下，确实XLNet相对Bert有很大幅度的提升。就像我们之前说的，感觉Bert打开两阶段模式的魔法盒开关后，在这条路上，会有越来越多的同行者，而XLNet就是其中比较引人注目的一位。当然，我估计很快我们会看到更多的这个模式下的新工作。未来两年，在两阶段新模式（预训练+Finetuning）下，应该会有更多的好工作涌现出来。根本原因在于：这个模式的潜力还没有被充分挖掘，貌似还有很大的提升空间。当然，这也意味着NLP在未来两年会有各种技术或者应用的突破，现在其实是进入NLP领域非常好的时机。原因有两个，一个是NLP正面临一个技术栈大的改朝换代的时刻，有很多空白等着你去填补，容易出成绩；另外一点，貌似Bert+Transformer有统一NLP各个应用领域的趋向，这意味着此时进入NLP领域，具备学习成本非常低的好处，和之前相比，投入产出比非常合算。这是两个原因。当然，即使如此，想要学好NLP，持续的精力投入是必不可少的。有句老话说得好：“永恒的爱大约持续三个月”，这句话其实对于很多对NLP感兴趣的同学也成立：“对NLP的永恒的热情大约能够持续3到5天”，希望真的有兴趣的同学能坚持一下，起码持续7到8天，凑够一个星期…..\u003C\u002Fp\u003E\u003Cp\u003E那么XLNet和Bert比，有什么异同？有什么模型方面的改进？在哪些场景下特别有效？原因又是什么？本文通过论文思想解读及实验结果分析，试图回答上述问题。\u003C\u002Fp\u003E\u003Cp\u003E首先，XLNet引入了自回归语言模型以及自编码语言模型的提法，这个思维框架我觉得挺好的，可以先简单说明下。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E自回归语言模型（Autoregressive LM）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E   在ELMO／BERT出来之前，大家通常讲的语言模型其实是根据上文内容预测下一个可能跟随的单词，就是常说的自左向右的语言模型任务，或者反过来也行，就是根据下文预测前面的单词，这种类型的LM被称为自回归语言模型。GPT 就是典型的自回归语言模型。ELMO尽管看上去利用了上文，也利用了下文，但是本质上仍然是自回归LM，这个跟模型具体怎么实现有关系。ELMO是做了两个方向（从左到右以及从右到左两个方向的语言模型），但是是分别有两个方向的自回归LM，然后把LSTM的两个方向的隐节点状态拼接到一起，来体现双向语言模型这个事情的。所以其实是两个自回归语言模型的拼接，本质上仍然是自回归语言模型。\u003C\u002Fp\u003E\u003Cp\u003E自回归语言模型有优点有缺点，缺点是只能利用上文或者下文的信息，不能同时利用上文和下文的信息，当然，貌似ELMO这种双向都做，然后拼接看上去能够解决这个问题，因为融合模式过于简单，所以效果其实并不是太好。它的优点，其实跟下游NLP任务有关，比如生成类NLP任务，比如文本摘要，机器翻译等，在实际生成内容的时候，就是从左向右的，自回归语言模型天然匹配这个过程。而Bert这种DAE模式，在生成类NLP任务中，就面临训练过程和应用过程不一致的问题，导致生成类的NLP任务到目前为止都做不太好。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E自编码语言模型（Autoencoder LM）\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E自回归语言模型只能根据上文预测下一个单词，或者反过来，只能根据下文预测前面一个单词。相比而言，Bert通过在输入X中随机Mask掉一部分单词，然后预训练过程的主要任务之一是根据上下文单词来预测这些被Mask掉的单词，如果你对Denoising Autoencoder比较熟悉的话，会看出，这确实是典型的DAE的思路。那些被Mask掉的单词就是在输入侧加入的所谓噪音。类似Bert这种预训练模式，被称为DAE LM。\u003C\u002Fp\u003E\u003Cp\u003E这种DAE LM的优缺点正好和自回归LM反过来，它能比较自然地融入双向语言模型，同时看到被预测单词的上文和下文，这是好处。缺点是啥呢？主要在输入侧引入[Mask]标记，导致预训练阶段和Fine-tuning阶段不一致的问题，因为Fine-tuning阶段是看不到[Mask]标记的。DAE吗，就要引入噪音，[Mask] 标记就是引入噪音的手段，这个正常。\u003C\u002Fp\u003E\u003Cp\u003EXLNet的出发点就是：能否融合自回归LM和DAE LM两者的优点。就是说如果站在自回归LM的角度，如何引入和双向语言模型等价的效果；如果站在DAE LM的角度看，它本身是融入双向语言模型的，如何抛掉表面的那个[Mask]标记，让预训练和Fine-tuning保持一致。当然，XLNet还讲到了一个Bert被Mask单词之间相互独立的问题，我相信这个不太重要，原因后面会说。当然，我认为这点不重要的事情，纯粹是个人观点，出错难免，看看就完了，不用较真。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003EXLNet做了些什么\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E上文说过，Bert这种自编码语言模型的好处是：能够同时利用上文和下文，所以信息利用充分。对于很多NLP任务而言，典型的比如阅读理解，在解决问题的时候，是能够同时看到上文和下文的，所以当然应该把下文利用起来。在Bert原始论文中，与GPT1.0的实验对比分析也可以看出来，BERT相对GPT 1.0的性能提升，主要来自于双向语言模型与单向语言模型的差异。这是Bert的好处，很明显，Bert之后的改进模型，如果不能把双向语言模型用起来，那明显是很吃亏的。当然，GPT 2.0的作者不信这个邪，坚持沿用GPT 1.0 单向语言模型的旧瓶，装进去了更高质量更大规模预训练数据的新酒，而它的实验结果也说明了，如果想改善预训练语言模型，走这条扩充预序列模型训练数据的路子，是个多快好但是不省钱的方向。这也进一步说明了，预训练LM这条路，还远远没有走完，还有很大的提升空间，比如最简单的提升方法就是加大数据规模，提升数据质量。\u003C\u002Fp\u003E\u003Cp\u003E但是Bert的自编码语言模型也有对应的缺点，就是XLNet在文中指出的，第一个预训练阶段因为采取引入[Mask]标记来Mask掉部分单词的训练模式，而Fine-tuning阶段是看不到这种被强行加入的Mask标记的，所以两个阶段存在使用模式不一致的情形，这可能会带来一定的性能损失；另外一个是，Bert在第一个预训练阶段，假设句子中多个单词被Mask掉，这些被Mask掉的单词之间没有任何关系，是条件独立的，而有时候这些单词之间是有关系的，XLNet则考虑了这种关系（关于这点原因是否可靠，后面会专门分析）。\u003C\u002Fp\u003E\u003Cp\u003E上面两点是XLNet在第一个预训练阶段，相对Bert来说要解决的两个问题。\u003C\u002Fp\u003E\u003Cp\u003E其实从另外一个角度更好理解XLNet的初衷和做法，我觉得这个估计是XLNet作者真正的思考出发点，是啥呢？就是说自回归语言模型有个缺点，要么从左到右，要么从右到左，尽管可以类似ELMO两个都做，然后再拼接的方式。但是跟Bert比，效果明显不足够好（这里面有RNN弱于Transformer的因素，也有双向语言模型怎么做的因素）。那么，能不能类似Bert那样，比较充分地在自回归语言模型中，引入双向语言模型呢？因为Bert已经证明了这是非常关键的一点。这一点，想法简单，但是看上去貌似不太好做，因为从左向右的语言模型，如果我们当前根据上文，要预测某个单词Ti，那么看上去它没法看到下文的内容。具体怎么做才能让这个模型：看上去仍然是从左向右的输入和预测模式，但是其实内部已经引入了当前单词的下文信息呢？XLNet在模型方面的主要贡献其实是在这里。\u003C\u002Fp\u003E\u003Cp\u003E那么XLNet是怎么做到这一点的呢？其实思路也比较简洁，可以这么思考：XLNet仍然遵循两阶段的过程，第一个阶段是语言模型预训练阶段；第二阶段是任务数据Fine-tuning阶段。它主要希望改动第一个阶段，就是说不像Bert那种带Mask符号的Denoising-autoencoder的模式，而是采用自回归LM的模式。就是说，看上去输入句子X仍然是自左向右的输入，看到Ti单词的上文Context_before，来预测Ti这个单词。但是又希望在Context_before里，不仅仅看到上文单词，也能看到Ti单词后面的下文Context_after里的下文单词，这样的话，Bert里面预训练阶段引入的Mask符号就不需要了，于是在预训练阶段，看上去是个标准的从左向右过程，Fine-tuning当然也是这个过程，于是两个环节就统一起来。当然，这是目标。剩下是怎么做到这一点的问题。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-05d785e9d8f810d118e4fa93f8e9b39f_b.jpg\" data-rawwidth=\"1680\" data-rawheight=\"1228\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1680\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-05d785e9d8f810d118e4fa93f8e9b39f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1680&#39; height=&#39;1228&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"1680\" data-rawheight=\"1228\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1680\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-05d785e9d8f810d118e4fa93f8e9b39f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-05d785e9d8f810d118e4fa93f8e9b39f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E那么，怎么能够在单词Ti的上文中Contenxt_before中揉入下文Context_after的内容呢？你可以想想。XLNet是这么做的，在预训练阶段，引入Permutation Language Model的训练目标。什么意思呢？就是说，比如包含单词Ti的当前输入的句子X，由顺序的几个单词构成，比如x1,x2,x3,x4四个单词顺序构成。我们假设，其中，要预测的单词Ti是x3，位置在Position 3，要想让它能够在上文Context_before中，也就是Position 1或者Position 2的位置看到Position 4的单词x4。可以这么做：假设我们固定住x3所在位置，就是它仍然在Position 3，之后随机排列组合句子中的4个单词，在随机排列组合后的各种可能里，再选择一部分作为模型预训练的输入X。比如随机排列组合后，抽取出x4,x2，x3,x1这一个排列组合作为模型的输入X。于是，x3就能同时看到上文x2，以及下文x4的内容了。这就是XLNet的基本思想，所以说，看了这个就可以理解上面讲的它的初衷了吧：看上去仍然是个自回归的从左到右的语言模型，但是其实通过对句子中单词排列组合，把一部分Ti下文的单词排到Ti的上文位置中，于是，就看到了上文和下文，但是形式上看上去仍然是从左到右在预测后一个单词。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-948e085be7a9a2eb7eac2d12069b1a93_b.jpg\" data-rawwidth=\"1484\" data-rawheight=\"838\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"1484\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-948e085be7a9a2eb7eac2d12069b1a93_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1484&#39; height=&#39;838&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"1484\" data-rawheight=\"838\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1484\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-948e085be7a9a2eb7eac2d12069b1a93_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-948e085be7a9a2eb7eac2d12069b1a93_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E当然，上面讲的仍然是基本思想。难点其实在于具体怎么做才能实现上述思想。首先，需要强调一点，尽管上面讲的是把句子X的单词排列组合后，再随机抽取例子作为输入，但是，实际上你是不能这么做的，因为Fine-tuning阶段你不可能也去排列组合原始输入。所以，就必须让预训练阶段的输入部分，看上去仍然是x1,x2,x3,x4这个输入顺序，但是可以在Transformer部分做些工作，来达成我们希望的目标。具体而言，XLNet采取了Attention掩码的机制，你可以理解为，当前的输入句子是X，要预测的单词Ti是第i个单词，前面1到i-1个单词，在输入部分观察，并没发生变化，该是谁还是谁。但是在Transformer内部，通过Attention掩码，从X的输入单词里面，也就是Ti的上文和下文单词中，随机选择i-1个，放到Ti的上文位置中，把其它单词的输入通过Attention掩码隐藏掉，于是就能够达成我们期望的目标（当然这个所谓放到Ti的上文位置，只是一种形象的说法，其实在内部，就是通过Attention Mask，把其它没有被选到的单词Mask掉，不让它们在预测单词Ti的时候发生作用，如此而已。看着就类似于把这些被选中的单词放到了上文Context_before的位置了）。具体实现的时候，XLNet是用“双流自注意力模型”实现的，细节可以参考论文，但是基本思想就如上所述，双流自注意力机制只是实现这个思想的具体方式，理论上，你可以想出其它具体实现方式来实现这个基本思想，也能达成让Ti看到下文单词的目标。\u003C\u002Fp\u003E\u003Cp\u003E这里简单说下“双流自注意力机制”，一个是内容流自注意力，其实就是标准的Transformer的计算过程；主要是引入了Query流自注意力，这个是干嘛的呢？其实就是用来代替Bert的那个[Mask]标记的，因为XLNet希望抛掉[Mask]标记符号，但是比如知道上文单词x1,x2，要预测单词x3，此时在x3对应位置的Transformer最高层去预测这个单词，但是输入侧不能看到要预测的单词x3，Bert其实是直接引入[Mask]标记来覆盖掉单词x3的内容的，等于说[Mask]是个通用的占位符号。而XLNet因为要抛掉[Mask]标记，但是又不能看到x3的输入，于是Query流，就直接忽略掉x3输入了，只保留这个位置信息，用参数w来代表位置的embedding编码。其实XLNet只是扔了表面的[Mask]占位符号，内部还是引入Query流来忽略掉被Mask的这个单词。和Bert比，只是实现方式不同而已。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2bb1a60af4fe2fa751647fdce48e337c_b.jpg\" data-rawwidth=\"2824\" data-rawheight=\"1544\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2824\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2bb1a60af4fe2fa751647fdce48e337c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2824&#39; height=&#39;1544&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2824\" data-rawheight=\"1544\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2824\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2bb1a60af4fe2fa751647fdce48e337c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2bb1a60af4fe2fa751647fdce48e337c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E上面说的Attention掩码，我估计你还是没了解它的意思，我再用例子解释一下。Attention Mask的机制，核心就是说，尽管当前输入看上去仍然是x1-&gt;x2-&gt;x3-&gt;x4，但是我们已经改成随机排列组合的另外一个顺序x3-&gt;x2-&gt;x4-&gt;x1了，如果用这个例子用来从左到右训练LM，意味着当预测x2的时候，它只能看到上文x3；当预测x4的时候，只能看到上文x3和x2，以此类推……这样，比如对于x2来说，就看到了下文x3了。这种在输入侧维持表面的X句子单词顺序，但是其实在Transformer内部，看到的已经是被重新排列组合后的顺序，是通过Attention掩码来实现的。如上图所示，输入看上去仍然是x1,x2,x3,x4，可以通过不同的掩码矩阵，让当前单词Xi只能看到被排列组合后的顺序x3-&gt;x2-&gt;x4-&gt;x1中自己前面的单词。这样就在内部改成了被预测单词同时看到上下文单词，但是输入侧看上去仍然维持原先的单词顺序了。关键要看明白上图右侧那个掩码矩阵，我相信很多人刚开始没看明白，因为我刚开始也没看明白，因为没有标出掩码矩阵的单词坐标，它的坐标是1-2-3-4，就是表面那个X的单词顺序，通过掩码矩阵，就能改成你想要的排列组合，并让当前单词看到它该看到的所谓上文，其实是掺杂了上文和下文的内容。这是attention mask来实现排列组合的背后的意思。\u003C\u002Fp\u003E\u003Cp\u003E上面讲的Permutation Language Model是XLNet的主要理论创新，所以介绍的比较多，从模型角度讲，这个创新还是挺有意思的，因为它开启了自回归语言模型如何引入下文的一个思路，相信对于后续工作会有启发。当然，XLNet不仅仅做了这些，它还引入了其它的因素，也算是一个当前有效技术的集成体。感觉XLNet就是Bert、GPT 2.0和Transformer XL的综合体变身，首先，它通过PLM预训练目标，吸收了Bert的双向语言模型；然后，GPT2.0的核心其实是更多更高质量的预训练数据，这个明显也被XLNet吸收进来了；再然后，Transformer XL的主要思想也被吸收进来，它的主要目标是解决Transformer对于长文档NLP应用不够友好的问题。\u003C\u002Fp\u003E\u003Cp\u003E以上是XLNet的几个主要改进点，有模型创新方面的，有其它模型引入方面的，也有数据扩充方面的。那么，这些因素各自起到了什么作用呢？在后面我们会谈。在谈不同因素各自作用之前，我们先分析下XLNet和Bert的异同问题。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E与Bert的预训练过程的异同问题\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E  尽管看上去，XLNet在预训练机制引入的Permutation Language Model这种新的预训练目标，和Bert采用Mask标记这种方式，有很大不同。其实你深入思考一下，会发现，两者本质是类似的。区别主要在于：Bert是直接在输入端显示地通过引入Mask标记，在输入侧隐藏掉一部分单词，让这些单词在预测的时候不发挥作用，要求利用上下文中其它单词去预测某个被Mask掉的单词；而XLNet则抛弃掉输入侧的Mask标记，通过Attention Mask机制，在Transformer内部随机Mask掉一部分单词（这个被Mask掉的单词比例跟当前单词在句子中的位置有关系，位置越靠前，被Mask掉的比例越高，位置越靠后，被Mask掉的比例越低），让这些被Mask掉的单词在预测某个单词的时候不发生作用。所以，本质上两者并没什么太大的不同，只是Mask的位置，Bert更表面化一些，XLNet则把这个过程隐藏在了Transformer内部而已。这样，就可以抛掉表面的[Mask]标记，解决它所说的预训练里带有[Mask]标记导致的和Fine-tuning过程不一致的问题。至于说XLNet说的，Bert里面被Mask掉单词的相互独立问题，也就是说，在预测某个被Mask单词的时候，其它被Mask单词不起作用，这个问题，你深入思考一下，其实是不重要的，因为XLNet在内部Attention Mask的时候，也会Mask掉一定比例的上下文单词，只要有一部分被Mask掉的单词，其实就面临这个问题。而如果训练数据足够大，其实不靠当前这个例子，靠其它例子，也能弥补被Mask单词直接的相互关系问题，因为总有其它例子能够学会这些单词的相互依赖关系。\u003C\u002Fp\u003E\u003Cp\u003E我相信，通过改造Bert的预训练过程，其实是可以模拟XLNet的Permutation Language Model过程的：Bert目前的做法是，给定输入句子X，随机Mask掉15%的单词，然后要求利用剩下的85%的单词去预测任意一个被Mask掉的单词，被Mask掉的单词在这个过程中相互之间没有发挥作用。如果我们把Bert的预训练过程改造成：对于输入句子，随机选择其中任意一个单词Ti，只把这个单词改成Mask标记，假设Ti在句子中是第i个单词，那么此时随机选择X中的任意i个单词，只用这i个单词去预测被Mask掉的单词。当然，这个过程理论上也可以在Transformer内采用attention mask来实现。如果是这样，其实Bert的预训练模式就和XLNet是基本等价的了。\u003C\u002Fp\u003E\u003Cp\u003E或者换个角度思考，假设仍然利用Bert目前的Mask机制，但是把Mask掉15%这个条件极端化，改成，每次一个句子只Mask掉一个单词，利用剩下的单词来预测被Mask掉的单词。那么，这个过程其实跟XLNet的PLM也是比较相像的，区别主要在于每次预测被Mask掉的单词的时候，利用的上下文更多一些（XLNet在实现的时候，为了提升效率，其实也是选择每个句子最后末尾的1\u002FK单词被预测，假设K=7，意味着一个句子X，只有末尾的1\u002F7的单词会被预测，这意味着什么呢？意味着至少保留了6\u002F7的Context单词去预测某个单词，对于最末尾的单词，意味着保留了所有的句子中X的其它单词，这其实和上面提到的Bert只保留一个被Mask单词是一样的）。或者我们站在Bert预训练的角度来考虑XLNet，如果XLNet改成对于句子X，只需要预测句子中最后一个单词，而不是最后的1\u002FK（就是假设K特别大的情况），那么其实和Bert每个输入句子只Mask掉一个单词，两者基本是等价的。\u003C\u002Fp\u003E\u003Cp\u003E当然，XLNet这种改造，维持了表面看上去的自回归语言模型的从左向右的模式，这个Bert做不到，这个有明显的好处，就是对于生成类的任务，能够在维持表面从左向右的生成过程前提下，模型里隐含了上下文的信息。所以看上去，XLNet貌似应该对于生成类型的NLP任务，会比Bert有明显优势。另外，因为XLNet还引入了Transformer XL的机制，所以对于长文档输入类型的NLP任务，也会比Bert有明显优势。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E哪些因素在起作用？\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E如上分析，XLNet有个好处，但是感觉同时也是个问题，那就是：XLNet其实同时引入了很多因素在模型里。说是好处，因为实验证明了这样效果确实好，即使是跟Bert_Large这种非常强的基准模型比也是，尤其是长文档任务，这个效果提升比较明显；说是问题，是因为其实应该在实验部分充分说明，如果模型起了作用，这些因素各自发挥了多大作用，尤其是在跟Bert进行对比的时候，感觉应该把数据规模这个变量磨平进行比较，因为这才是单纯的模型差异导致的性能差异，而不是训练数据量引发的差异。当然，XLNet最后一组实验是把这个预训练数据规模差异磨平后，和Bert比较的，所以信息含量更大些。而前面的几组实验，因为天然存在预训练数据量的差异，所以模型导致的差异到底有多大，看得不太明显。\u003C\u002Fp\u003E\u003Cp\u003E我们上文提到过，XLNet起作用的，如果宏观归纳一下，共有三个因素；\u003C\u002Fp\u003E\u003Cp\u003E1. 与Bert采取De-noising Autoencoder方式不同的新的预训练目标：Permutation Language Model(简称PLM)；这个可以理解为在自回归LM模式下，如何采取具体手段，来融入双向语言模型。这个是XLNet在模型角度比较大的贡献，确实也打开了NLP中两阶段模式潮流的一个新思路。\u003C\u002Fp\u003E\u003Cp\u003E2. 引入了Transformer-XL的主要思路：相对位置编码以及分段RNN机制。实践已经证明这两点对于长文档任务是很有帮助的；\u003C\u002Fp\u003E\u003Cp\u003E3. 加大增加了预训练阶段使用的数据规模；Bert使用的预训练数据是BooksCorpus和英文Wiki数据，大小13G。XLNet除了使用这些数据外，另外引入了Giga5，ClueWeb以及Common Crawl数据，并排掉了其中的一些低质量数据，大小分别是16G,19G和78G。可以看出，在预训练阶段极大扩充了数据规模，并对质量进行了筛选过滤。这个明显走的是GPT2.0的路线。\u003C\u002Fp\u003E\u003Cp\u003E所以实验部分需要仔细分析，提升到底是上述哪个因素或者是哪几个因素导致的性能提升？\u003C\u002Fp\u003E\u003Cp\u003E我们把实验分成几个部分来分析。\u003C\u002Fp\u003E\u003Cp\u003E首先，给人最大的印象是：XLNet对于阅读理解类任务，相对Bert，性能有极大幅度地提升。下面是论文报道的实验结果：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-368cb8e6f8b2eeacabe1d2638dd12cb2_b.jpg\" data-rawwidth=\"2838\" data-rawheight=\"1558\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2838\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-368cb8e6f8b2eeacabe1d2638dd12cb2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2838&#39; height=&#39;1558&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2838\" data-rawheight=\"1558\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2838\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-368cb8e6f8b2eeacabe1d2638dd12cb2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-368cb8e6f8b2eeacabe1d2638dd12cb2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c854303cd62b5ef22a0b2c2a01a72f2_b.jpg\" data-rawwidth=\"2880\" data-rawheight=\"1800\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2880\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c854303cd62b5ef22a0b2c2a01a72f2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2880&#39; height=&#39;1800&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2880\" data-rawheight=\"1800\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2880\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c854303cd62b5ef22a0b2c2a01a72f2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9c854303cd62b5ef22a0b2c2a01a72f2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E其中，RACE和SQuAD 2.0是文档长度较长的阅读理解任务，任务难度也相对高。可以看出，在这两个任务中，XLNet相对 Bert_Large，确实有大幅性能提升（Race提升13.5%,SQuAD 2.0 F1指标提升8.6）。在Squad1.1上提升尽管稍微小些，F1提升3.9%，但是因为基准高，所以提升也比较明显。\u003C\u002Fp\u003E\u003Cp\u003E说XLNet在阅读理解，尤其是长文档的阅读理解中，性能大幅超过Bert，这个是没疑问的。但是，因为XLNet融入了上文说的三个因素，所以不确定每个因素在其中起的作用有多大，而对于长文档，Transformer XL的引入肯定起了比较大的作用，Bert天然在这种类型任务中有缺点，其它两类因素的作用不清楚。感觉这里应该增加一个基准，就是Bert用与XLNet相同大小的预训练数据做，这样抹平数据量差异，更好比较模型差异带来的效果差异。当然，我觉得即使是这样，XLNet应该仍然是比Bert效果好的，只是可能不会差距这么大，因为XLNet的长文档优势肯定会起作用。\u003C\u002Fp\u003E\u003Cp\u003E下面我们看下其它类型的NLP任务。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-18c8752f5c9dac8c6de11337a8efb453_b.jpg\" data-rawwidth=\"2702\" data-rawheight=\"1520\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2702\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-18c8752f5c9dac8c6de11337a8efb453_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2702&#39; height=&#39;1520&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2702\" data-rawheight=\"1520\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2702\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-18c8752f5c9dac8c6de11337a8efb453_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-18c8752f5c9dac8c6de11337a8efb453_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003EGLUE是个综合的NLP任务集合，包含各种类型的任务，因为ensemble模式里面包含了各种花式的trick，所以重点看上面一组实验，这里比较单纯。从实验数据看，XLNet相对Bert也有性能提升，当然不像阅读理解提升那么大，而且性能提升比较大的集中在RTE，MNLI和COLA数据集合，其它任务提升效果还好。而我一直觉得，RTE在GLUE里，是个神奇的存在，如果没有它，很多论文的效果可能没法看，这个是闲话，先不讲了，后面我会单说。\u003C\u002Fp\u003E\u003Cp\u003E 当然，仍然不确定这种性能提升主要来自于XLNet的哪个因素，或者哪几个因素各自的贡献，尤其是如果Bert加大预训练数据规模后，两者性能差异有多大。感觉这里Transformer XL的因素可能发挥的作用不会太大，其它两个因素在起作用，但是作用未知，这里感觉应该补充其它实验。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78cc6b83fcf24f1f2b89922d217f597f_b.jpg\" data-rawwidth=\"2734\" data-rawheight=\"1530\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2734\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78cc6b83fcf24f1f2b89922d217f597f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2734&#39; height=&#39;1530&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2734\" data-rawheight=\"1530\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2734\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78cc6b83fcf24f1f2b89922d217f597f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78cc6b83fcf24f1f2b89922d217f597f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2d2651c3e9b5bd28237db65171baa46f_b.jpg\" data-rawwidth=\"2812\" data-rawheight=\"1554\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2812\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2d2651c3e9b5bd28237db65171baa46f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2812&#39; height=&#39;1554&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2812\" data-rawheight=\"1554\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2812\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2d2651c3e9b5bd28237db65171baa46f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2d2651c3e9b5bd28237db65171baa46f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E上面是文本分类任务和信息检索任务，可以看出，相对Bert，XLNet效果有提升，但是幅度不算大。仍然是上面的考虑，起作用的三个因素，到底哪个发挥多大作用，从数据方面看不太出来。\u003C\u002Fp\u003E\u003Cp\u003E下面一组实验可以仔细分析一下，这组实验是排除掉上述第三个数据规模因素的实验的对比，就是说XLNet用的是和Bert相同规模的预训练数据，所以与Bert对比更具备模型方面的可比较性，而没有数据规模的影响。实验结果如下：\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-86f738620973ec16395c99480db4239d_b.jpg\" data-rawwidth=\"2682\" data-rawheight=\"1526\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb\" width=\"2682\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-86f738620973ec16395c99480db4239d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2682&#39; height=&#39;1526&#39;&gt;&lt;\u002Fsvg&gt;\" data-rawwidth=\"2682\" data-rawheight=\"1526\" data-size=\"normal\" data-caption=\"\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2682\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-86f738620973ec16395c99480db4239d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-86f738620973ec16395c99480db4239d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E如果仔细分析实验数据，实验结果说明：\u003C\u002Fp\u003E\u003Cp\u003E因为和Bert比较，XLNet使用相同的预训练数据。所以两者的性能差异来自于：Permutation Language Model预训练目标以及Transformer XL的长文档因素。而从中可以看出，DAE+Transformer XL体现的是长文档因素的差异，和Bert比，Race提升1个点，SQuAD F1提升3个点，MNLI提升0.5个点，SST-2性能稍微下降。这是Transformer XL因素解决长文档因素带来的收益，很明显，长文档阅读理解任务提升比较明显，其它任务提升不太明显。\u003C\u002Fp\u003E\u003Cp\u003E 而通过XLNet进一步和DAE+Transformer XL及Bert比，这一点应该拆解出Permutation Language Model和Mask的方式差异。可以看出：XLNet相对DAE+Transformer XL来说，Race进一步提升1个点左右；SQuAD进一步提升1.8个点左右，NMLI提升1个点左右，SST-B提升不到1个点。虽然不精准，但是大致是能说明问题的，这个应该大致是PLM带来的模型收益。可以看出，PLM还是普遍有效的，但是提升幅度并非特别巨大。\u003C\u002Fp\u003E\u003Cp\u003E 如果我们结合前面Race和SQuAD的实验结果看（上面两组实验是三个因素的作用，后面是排除掉数据量差异的结果，所以两者的差距，很可能就是第三个因素：数据规模导致的差异，当然，因为一个是Bert_base，一个是Bert_Large，所以不具备完全可比性，但是大致估计不会偏离真实结论太远），Race数据集合三因素同时具备的XLNet，超过Bert绝对值大约9个多百分点，Transformer因素+PLM因素估计贡献大约在2到4个点之间，那么意味着预训练数据量导致的差异大概在4到5个点左右；类似的，可以看出，SQuAD 2.0中，预训练数据量导致的差异大约在2到3个点左右，也就是说，估计训练数据量带来的提升，在阅读理解任务中大约占比30%到40%左右。 \u003C\u002Fp\u003E\u003Cp\u003E  如果从实验结果归纳一下的话，可以看出：XLNet综合而言，效果是优于Bert的，尤其是在长文档类型任务，效果提升明显。如果进一步拆解的话，因为对比实验不足，只能做个粗略的结论：预训练数据量的提升，大概带来30%左右的性能提升，其它两个模型因素带来剩余的大约70%的性能提升。当然，这个主要指的是XLNet性能提升比较明显的阅读理解类任务而言。对于其它类型任务，感觉Transformer XL的因素贡献估计不会太大，主要应该是其它两个因素在起作用。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E对NLP应用任务的影响\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E XLNet其实本质上还是ELMO／GPT／Bert这一系列两阶段模型的进一步延伸。在将自回归LM方向引入双向语言模型方面，感觉打开了一个新思路，这点还是非常对人有启发的。当然，如果深入思考，其实和Bert并没有太大的不同。\u003C\u002Fp\u003E\u003Cp\u003E 如果让我推论下XLNet的出现，对后续NLP工作的影响，我觉得跟Bert比，最直接的影响应该有两个，一个是对于Bert长文档的应用，因为Transformer天然对长文档任务处理有弱点，所以XLNet对于长文档NLP任务相比Bert应该有直接且比较明显的性能提升作用，它在论文中也证明了这点。所以，以后长文档类型的NLP应用，XLNet明显跟Bert比占优势。当然，你说我把Transformer XL的因素引入Bert，然后继续在Bert上做改进，明显这也是可以的。\u003C\u002Fp\u003E\u003Cp\u003E 第二点，对于生成类的NLP任务，到目前为止，尽管出了一些改进模型，但是从效果看，Bert仍然不能很好地处理。而因为XLNet的预训练模式天然符合下游任务序列生成结果，所以按理说能够直接通过引入XLNet来改进生成类NLP任务的效果。所以，这点估计是XLNet会明显占优势的一个领域。\u003C\u002Fp\u003E\u003Cp\u003E 可以预计的是，很快我们就会看到XLNet在文本摘要，机器翻译，信息检索…..等符合上述XLNet应用领域特点和优势领域的应用结果，以及在这些任务上的进一步改进模型。当然，这个有点比手速的意思，有意者请尽快动手把结果扔出来。\u003C\u002Fp\u003E\u003Cp\u003E 又给你了一个拼手速的机会，加油吧，少年！\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19551275","type":"topic","id":"19551275","name":"人工智能"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19813032","type":"topic","id":"19813032","name":"深度学习（Deep Learning）"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19560026","type":"topic","id":"19560026","name":"自然语言处理"}],"voteupCount":1472,"voting":0,"column":{"description":"","canManage":false,"intro":"深度学习领域前沿进展科普","isFollowing":false,"urlToken":"c_188941548","id":"c_188941548","articlesCount":25,"acceptSubmission":true,"title":"深度学习前沿笔记","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_188941548","commentPermission":"all","created":1526350240,"updated":1599154668,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a19621dc409ca054f1630c09679a41ff_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5.jpg?source=172ae18b","uid":"37478916423680","userType":"people","isFollowing":false,"urlToken":"zhang-jun-lin-76","id":"147bf0c743d6aa5ccea428a6f4cc7186","description":"Heil Hydra！嗯","name":"张俊林","isAdvertiser":false,"headline":"你所不知道的事","gender":1,"url":"\u002Fpeople\u002F147bf0c743d6aa5ccea428a6f4cc7186","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":14602,"type":"column"},"commentCount":106,"contributions":[{"id":21124594,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"深度学习领域前沿进展科普","isFollowing":false,"urlToken":"c_188941548","id":"c_188941548","articlesCount":25,"acceptSubmission":true,"title":"深度学习前沿笔记","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_188941548","commentPermission":"all","created":1526350240,"updated":1599154668,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a19621dc409ca054f1630c09679a41ff_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5.jpg?source=172ae18b","uid":"37478916423680","userType":"people","isFollowing":false,"urlToken":"zhang-jun-lin-76","id":"147bf0c743d6aa5ccea428a6f4cc7186","description":"Heil Hydra！嗯","name":"张俊林","isAdvertiser":false,"headline":"你所不知道的事","gender":1,"url":"\u002Fpeople\u002F147bf0c743d6aa5ccea428a6f4cc7186","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":14602,"type":"column"}},{"id":28168750,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"收集看到的高赞解析和回答","isFollowing":false,"urlToken":"c_1280888532622143488","id":"c_1280888532622143488","articlesCount":35,"acceptSubmission":false,"title":"好文","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1280888532622143488","commentPermission":"all","created":1598167624,"updated":1598167624,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf67c60ca2f1ed53b0cd05cfe90e173a.jpg?source=172ae18b","uid":"1158012259165970432","userType":"people","isFollowing":false,"urlToken":"lizhuolin-75","id":"208d525cb5ff7cd17bda5025e976fa6a","description":"","name":"lizhuolin","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002F208d525cb5ff7cd17bda5025e976fa6a","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cf67c60ca2f1ed53b0cd05cfe90e173a_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":62,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":9,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":1196,"isNormal":true,"status":0,"shareText":"XLNet:运行机制及和Bert的异同比较 - 来自知乎专栏「深度学习前沿笔记」，作者: 张俊林 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F70257427 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":38,"visibleOnlyToAuthor":false,"hasColumn":true,"republishers":[{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf67c60ca2f1ed53b0cd05cfe90e173a.jpg?source=172ae18b","uid":"1158012259165970432","userType":"people","isFollowing":false,"urlToken":"lizhuolin-75","id":"208d525cb5ff7cd17bda5025e976fa6a","description":"","name":"lizhuolin","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002F208d525cb5ff7cd17bda5025e976fa6a","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cf67c60ca2f1ed53b0cd05cfe90e173a_l.jpg?source=172ae18b","isOrg":false,"type":"people"}]}},"columns":{"c_188941548":{"description":"","canManage":false,"intro":"深度学习领域前沿进展科普","isFollowing":false,"urlToken":"c_188941548","id":"c_188941548","articlesCount":25,"acceptSubmission":true,"title":"深度学习前沿笔记","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_188941548","commentPermission":"all","created":1526350240,"updated":1599154668,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a19621dc409ca054f1630c09679a41ff_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5.jpg?source=172ae18b","uid":"37478916423680","userType":"people","isFollowing":false,"urlToken":"zhang-jun-lin-76","id":"147bf0c743d6aa5ccea428a6f4cc7186","description":"Heil Hydra！嗯","name":"张俊林","isAdvertiser":false,"headline":"你所不知道的事","gender":1,"url":"\u002Fpeople\u002F147bf0c743d6aa5ccea428a6f4cc7186","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e2f0287f28b654a03136ca1900c92cb5_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":14602,"type":"column"},"c_1280888532622143488":{"description":"","canManage":false,"intro":"收集看到的高赞解析和回答","isFollowing":false,"urlToken":"c_1280888532622143488","id":"c_1280888532622143488","articlesCount":35,"acceptSubmission":false,"title":"好文","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1280888532622143488","commentPermission":"all","created":1598167624,"updated":1598167624,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cf67c60ca2f1ed53b0cd05cfe90e173a.jpg?source=172ae18b","uid":"1158012259165970432","userType":"people","isFollowing":false,"urlToken":"lizhuolin-75","id":"208d525cb5ff7cd17bda5025e976fa6a","description":"","name":"lizhuolin","isAdvertiser":false,"headline":"","gender":1,"url":"\u002Fpeople\u002F208d525cb5ff7cd17bda5025e976fa6a","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cf67c60ca2f1ed53b0cd05cfe90e173a_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":62,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-qa_cl_guest-2","expPrefix":"qa_cl_guest","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-se_item-3","expPrefix":"se_item","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_andplay_d-2","expPrefix":"vd_andplay_d","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_hookupplay_an-2","expPrefix":"vd_hookupplay_an","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_timeguide-2","expPrefix":"vd_timeguide","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_video_replay-3","expPrefix":"vd_video_replay","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_zvideo_link-10","expPrefix":"vd_zvideo_link","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"zanswer-2","expPrefix":"zanswer","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false},{"expId":"recnew_2th-3","expPrefix":"recnew_2th","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false},{"expId":"captcha_v2-2_v7","expPrefix":"captcha_v2","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"Test_Punk-1_v2","expPrefix":"Test_Punk","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"meta_ebook-2_v1","expPrefix":"meta_ebook","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"club_fn-1_v4","expPrefix":"club_fn","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"general_1-2_v1","expPrefix":"general_1","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"correct_gpu-6_v5","expPrefix":"correct_gpu","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"correct_pos-4_v2","expPrefix":"correct_pos","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"ge_newbie3-1_v1","expPrefix":"ge_newbie3","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_cvr_boost-3_v1","expPrefix":"se_cvr_boost","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"se_sug_topic-1_v2","expPrefix":"se_sug_topic","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"rec_new2th-3_v1","expPrefix":"rec_new2th","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"hot_card","type":"Int","value":"0","chainId":"_gene_","layerId":"hot_card","key":108},{"id":"se_cvr_boost","type":"Int","value":"1","chainId":"_gene_","layerId":"se_cvr_boost","key":183},{"id":"se_sug_topic","type":"Int","value":"0","chainId":"_gene_","layerId":"se_sug_topic","key":230},{"id":"ge_video","type":"String","value":"0","chainId":"_gene_","layerId":"geli_layer_856","key":2831},{"id":"li_edu_page","type":"String","value":"old","chainId":"_all_","layerId":"lili_layer_580"},{"id":"ge_sug_v2","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_1000","key":3189},{"id":"ge_emoji","type":"String","value":"0","chainId":"_gene_","layerId":"getp_layer_827","key":3209},{"id":"tp_topic_style","type":"String","value":"0","chainId":"_all_","layerId":"tptp_layer_4"},{"id":"gue_video_replay","type":"String","value":"2","layerId":"guevd_layer_3"},{"id":"gue_playh_an","type":"String","value":"1","layerId":"guevd_layer_622"},{"id":"se_doc_cnt","type":"Int","value":"0","chainId":"_gene_","layerId":"uD1x","key":302},{"id":"rec_new2th","type":"Int","value":"0","chainId":"_gene_","layerId":"rec_new2th","key":320},{"id":"ge_rec_2th","type":"String","value":"11","chainId":"_gene_","layerId":"geli_layer_965","key":3023},{"id":"gue_fo_recom","type":"String","value":"0","layerId":"gueqa_layer_780"},{"id":"tp_dingyue_video","type":"String","value":"0","chainId":"_all_","layerId":"tptp_layer_4"},{"id":"gue_bullet_second","type":"String","value":"1","layerId":"guevd_layer_1"},{"id":"li_paid_answer_exp","type":"String","value":"0","chainId":"_all_","layerId":"lili_layer_3"},{"id":"li_panswer_topic","type":"String","value":"0","chainId":"_all_","layerId":"lili_layer_602"},{"id":"li_video_section","type":"String","value":"0","chainId":"_all_","layerId":"lili_layer_7"},{"id":"gue_goods_card","type":"String","value":"0","layerId":"gueqa_layer_1"},{"id":"gue_repost","type":"String","value":"0","layerId":"gueqa_layer_671"},{"id":"web_answer_list_ad","type":"String","value":"1","layerId":"webqa_layer_4"},{"id":"web_collection_guest","type":"String","value":"1","layerId":"webqa_layer_4"},{"id":"gue_recmess","type":"String","value":"0","layerId":"gueqa_layer_795"},{"id":"ge_sxzx","type":"String","value":"0","chainId":"_gene_","layerId":"gere_layer_990","key":3060},{"id":"ge_dipin_pre","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_1000","key":3124},{"id":"ge_upload","type":"String","value":"0","chainId":"_gene_","layerId":"geus_layer_839","key":2892},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_","layerId":"iosus_layer_1"},{"id":"webpImg","type":"Int","value":"1","layerId":"webpImg"},{"id":"ge_newbie3","type":"Int","value":"0","chainId":"_gene_","layerId":"ge_newbie3","key":180},{"id":"web_audit_01","type":"String","value":"case1","layerId":"webre_layer_1"},{"id":"ge_yuzhi_v1","type":"String","value":"1","chainId":"_gene_","layerId":"gese_layer_1029","key":3127},{"id":"ge_meta_ss","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_834","key":3079},{"id":"ge_rec_sup","type":"Int","value":"0","chainId":"_gene_","layerId":"ge_rec_sup","key":197},{"id":"li_vip_verti_search","type":"String","value":"0","chainId":"_all_","layerId":"lili_layer_2"},{"id":"web_column_auto_invite","type":"String","value":"0","layerId":"webqa_layer_1"},{"id":"zr_slotpaidexp","type":"String","value":"1","chainId":"_all_","layerId":"zrrec_layer_5"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_","layerId":"pfus_layer_718"},{"id":"gue_bulletmb","type":"String","value":"0","layerId":"guevd_layer_812"},{"id":"gue_vid_tab","type":"String","value":"0","layerId":"guevd_layer_900"},{"id":"show_ad","type":"Int","value":"0","chainId":"_gene_","layerId":"show_ad","key":27},{"id":"ge_hard_s_ma","type":"String","value":"0","chainId":"_gene_","layerId":"geli_layer_856","key":3031},{"id":"gue_art_ui","type":"String","value":"0","layerId":"gueqa_layer_647"},{"id":"tp_contents","type":"String","value":"2","chainId":"_all_","layerId":"tptp_layer_627"},{"id":"Test_Punk","type":"Int","value":"0","layerId":"Test_Punk"},{"id":"pfd_newbie2","type":"Int","value":"0","chainId":"_gene_","layerId":"pfd_newbie2","key":71},{"id":"se_4a","type":"Int","value":"0","chainId":"_gene_","layerId":"rtiq","key":335},{"id":"web_heifetz_grow_ad","type":"String","value":"1","layerId":"webgw_layer_3"},{"id":"recnew_2th","type":"Int","value":"21","chainId":"_gene_","layerId":"recnew_2th","key":67},{"id":"ge_infinity6","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_815","key":2817},{"id":"ge_entity","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_946","key":3036},{"id":"ge_prf_rec","type":"String","value":"0","chainId":"_gene_","layerId":"getop_layer_991","key":3040},{"id":"gue_sharp","type":"String","value":"1","layerId":"guevd_layer_686"},{"id":"zanswer","type":"Int","value":"1","layerId":"zanswer"},{"id":"ge_search_ui","type":"String","value":"1","chainId":"_gene_","layerId":"gese_layer_838","key":2898},{"id":"se_ffzx_jushen1","type":"String","value":"0","chainId":"_all_","layerId":"sese_layer_4"},{"id":"gue_bullet_guide","type":"String","value":"发个弹幕聊聊…","layerId":"guevd_layer_0"},{"id":"gue_v_serial","type":"String","value":"1","layerId":"guevd_layer_695"},{"id":"captcha_v2","type":"Int","value":"1","layerId":"captcha_v2"},{"id":"meta_ebook","type":"Int","value":"1","layerId":"meta_ebook"},{"id":"web_scl_rec","type":"String","value":"0","layerId":"webgw_layer_759"},{"id":"gue_card_test","type":"String","value":"1","layerId":"gueqa_layer_2"},{"id":"gue_q_share","type":"String","value":"0","layerId":"gueqa_layer_647"},{"id":"ge_sug_rep","type":"String","value":"1","chainId":"_gene_","layerId":"gese_layer_1034","key":3158},{"id":"ge_guess","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_938","key":2912},{"id":"ge_newyanzhi","type":"String","value":"0","chainId":"_gene_","layerId":"geus_layer_1019","key":2788},{"id":"pf_adjust","type":"String","value":"0","chainId":"_all_","layerId":"pfus_layer_9"},{"id":"gue_zvideo_link","type":"String","value":"1","layerId":"guevd_layer_2"},{"id":"gue_andplayd","type":"String","value":"1","layerId":"guevd_layer_686"},{"id":"gue_iosplay","type":"String","value":"0","layerId":"guevd_layer_896"},{"id":"club_fn","type":"Int","value":"1","layerId":"club_fn"},{"id":"pfd_newbie","type":"Int","value":"0","chainId":"_gene_","layerId":"pfd_newbie","key":63},{"id":"web_login","type":"String","value":"0","layerId":"webgw_layer_759"},{"id":"li_sp_mqbk","type":"String","value":"0","chainId":"_all_","layerId":"lili_layer_748"},{"id":"gue_cdzixun","type":"String","value":"0","layerId":"gueqa_layer_3"},{"id":"gue_visit_n_artcard","type":"String","value":"1","layerId":"gueqa_layer_579"},{"id":"qap_question_author","type":"String","value":"0","chainId":"_all_","layerId":"qapqa_layer_2"},{"id":"zr_expslotpaid","type":"String","value":"1","chainId":"_all_","layerId":"zrrec_layer_11"},{"id":"ge_v_rank_v3","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_1047","key":2966},{"id":"ge_usercard1","type":"String","value":"0","chainId":"_gene_","layerId":"gese_layer_742","key":2740},{"id":"correct_gpu","type":"Int","value":"5","chainId":"_gene_","layerId":"correct_gpu","key":66},{"id":"se_fix_ebook","type":"Int","value":"0","chainId":"_gene_","layerId":"se_fix_ebook","key":103},{"id":"web_sem_ab","type":"String","value":"1","layerId":"webgw_layer_3"},{"id":"gue_art2qa","type":"String","value":"0","layerId":"gueqa_layer_579"},{"id":"ge_relation2","type":"String","value":"1","chainId":"_gene_","layerId":"gese_layer_815","key":2796},{"id":"se_mix_daily","type":"Int","value":"0","chainId":"_gene_","layerId":"se_mix_daily","key":315},{"id":"gue_messrec","type":"String","value":"0","layerId":"gueqa_layer_769"},{"id":"qap_question_visitor","type":"String","value":" 0","chainId":"_all_","layerId":"qapqa_layer_2"},{"id":"ge_item","type":"String","value":"2","chainId":"_gene_","layerId":"gese_layer_945","key":2971},{"id":"tp_zrec","type":"String","value":"0","chainId":"_all_","layerId":"tptp_layer_619"},{"id":"ge_newcard","type":"String","value":"3","chainId":"_gene_","layerId":"geus_layer_839","key":2997},{"id":"gue_video_guide","type":"String","value":"1","layerId":"guevd_layer_625"},{"id":"general_1","type":"Int","value":"2","chainId":"_gene_","layerId":"general_1","key":8},{"id":"correct_pos","type":"Int","value":"2","chainId":"_gene_","layerId":"correct_pos","key":104},{"id":"web_answerlist_ad","type":"String","value":"0","layerId":"webqa_layer_1"},{"id":"gue_profile_video","type":"String","value":"1","layerId":"guevd_layer_5"}],"chains":[{"chainId":"_all_"}],"encodedParams":"Ck5sALcA5gAPC3UMiQwuAUABzwv0CzQMTAu0ADcMBwzFABsA1wtHAE8BQwABC9wL4AtSC1YMYAvkCj8Algu0CkIAZwDsCjsBmwu1CwgAaAASJwABAAAAAAAACwAAAAABAAAAAAAAFQAAAAEBAAAAAAAFAAEAAgMCAg=="},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F87.0.4280.141 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F70257427","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F70257427","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"baiduSearch":false,"googleSearch":true,"miniProgram":false,"xiaomi":false},"theme":"light","enableShortcut":true,"referer":"https:\u002F\u002Fwww.google.com\u002F","xUDId":"AMDXQDElJhKPTuaokJ4gj2zgwesVBJGwYQo=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"福州","countryName":"中国","regionName":"福建","countryCode":"CN"},"logged":false,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{},"videoSupport":{},"mcnManage":{},"tasks":{},"recentlyCreated":[]},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"room":{"meta":{},"isFetching":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"c_188941548","c_1280888532622143488"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0},"visible":false}},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"club":{}},"republish":{}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/vendor.8d94b1270b86debd0e1c.js.下载"></script><script src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/column.app.917b778ebd77fa1c91d0.js.下载"></script><script src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/hm.js.下载" async=""></script><script src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/zap.js.下载"></script><script src="./XLNet_运行机制及和Bert的异同比较 - 知乎_files/push.js.下载"></script><div><div style="display: none;">想来知乎工作？请发送邮件到 jobs@zhihu.com</div></div><div><div><div class="css-8pdeid"></div></div></div><div><div><div class="Editable-languageSuggestions" style="left: -1179px; top: -999px;"><div><div class="Popover"><label class="Editable-languageSuggestionsInput Input-wrapper"><input autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete14-0" id="Popover13-toggle" aria-haspopup="true" aria-owns="Popover13-content" class="Input" placeholder="选择语言" value=""><svg class="Zi Zi--Select" fill="#afbdcf" viewBox="0 0 24 24" width="24" height="24"><path d="M12 16.183l2.716-2.966a.757.757 0 0 1 1.064.001.738.738 0 0 1 0 1.052l-3.247 3.512a.758.758 0 0 1-1.064 0L8.22 14.27a.738.738 0 0 1 0-1.052.758.758 0 0 1 1.063 0L12 16.183zm0-9.365L9.284 9.782a.758.758 0 0 1-1.064 0 .738.738 0 0 1 0-1.052l3.248-3.512a.758.758 0 0 1 1.065 0L15.78 8.73a.738.738 0 0 1 0 1.052.757.757 0 0 1-1.063.001L12 6.818z" fill-rule="evenodd"></path></svg></label></div></div></div></div></div></body></html>